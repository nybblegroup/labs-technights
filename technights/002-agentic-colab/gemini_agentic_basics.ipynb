{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWsncml-B986"
      },
      "source": [
        "# [AGENTIC GEMINI BASICS](https://colab.research.google.com/gist/LuisSala/3542b7f36e6c7fbe5ab4e3f138997c29/gemini_agentic_basics.ipynb)\n",
        "\n",
        "This notebook demonstrates the foundational concepts of agents without relying on the abstractions presented by sophisticated SDKs and related tooling.\n",
        "\n",
        "The idea being that the reader can try to understand \"how the engine words\" before \"building the car around it\".\n",
        "\n",
        "We apply the basic building blocks of model calling and structured outputs to build a sequential workflow-style agent and then a non-deterministic \"research\" agent\" using nothing more than the core Gemini SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_AL0NcpVBjI",
        "outputId": "9a38f67e-3a7f-462f-dfeb-e7543608e0c1"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-genai\n",
        "!pip install -U -q google-adk\n",
        "!pip install -U -q requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQz5Fz8DnJeB"
      },
      "source": [
        "# 1.0 - SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX_Dd8xvLSAM"
      },
      "source": [
        "## Authenticate with Google Cloud (Colab Only)\n",
        "Google Colab projects can authenticate against Google Cloud via the following calls. It is not required if running on Colab Enterprise or Vertex AI Workbench.\n",
        "\n",
        "Running the cell below sets up the \"[Application Default Credentials](https://cloud.google.com/docs/authentication/provide-credentials-adc).\" which are used by our SDKs to automatically authenticate against Google Cloud Services.\n",
        "\n",
        "In short, this is equivalent to the following gcloud CLI commands:\n",
        "```bash\n",
        "$ gcloud auth login\n",
        "$ gcloud auth application-default login\n",
        "```\n",
        "\n",
        "An authentication pop-up will appear, please accept the permissions before proceeding.\n",
        "\n",
        "### Alternative: Using Gemini API Keys\n",
        "Some of these code samples will only work with a Google Cloud account, but the basic Gemini SDK will also work via an API key that can be obtained from [Google AI Studio](https://aistudio.google.com).\n",
        "\n",
        "**Steps:**\n",
        "1. Get an API key from: https://aistudio.google.com/app/apikey\n",
        "2. Create a Colab \"secret\" called `AI_STUDIO_API_KEY` in the \"Secrets\" tab on the left hand side of Colab.\n",
        "3. Make sure that `PROJECT_ID` *is not* defined. This ensures that AI Studio's API key will be used instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "yA1RT-4CVdnK",
        "outputId": "c20a44ec-d254-4506-92d9-116da10c6c9b"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "import sys\n",
        "\n",
        "# Leave PROJECT_ID Blank to use an API Key instead\n",
        "PROJECT_ID = \"\" # @param {type: \"string\"}\n",
        "LOCATION = \"\" # @param {type: \"string\"}\n",
        "\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1CyIajvKWeH"
      },
      "source": [
        "## Configure GenAI Parameters\n",
        "\n",
        "This is just an example of the kinds of parameters you can configure. Of these, only the `MODEL_ID` variable is used elsewhere in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ox6VsXjsZIaB"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# The default safety settings should be sufficient for most scenarios.\n",
        "# Optionally, developers can customize the safety settings.\n",
        "# Learn more at:\n",
        "# - https://googleapis.github.io/python-genai/index.html#safety-settings\n",
        "# - https://cloud.google.com/vertex-ai/generative-ai/docs/learn/responsible-ai\n",
        "CUSTOM_SAFETY_SETTINGS = [\n",
        "    types.SafetySetting(\n",
        "        category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        threshold=\"BLOCK_ONLY_HIGH\",\n",
        "    ),\n",
        "    types.SafetySetting(\n",
        "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        threshold=\"BLOCK_ONLY_HIGH\",\n",
        "    ),\n",
        "    types.SafetySetting(\n",
        "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        threshold=\"BLOCK_ONLY_HIGH\",\n",
        "    ),\n",
        "    types.SafetySetting(\n",
        "        category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "        threshold=\"BLOCK_ONLY_HIGH\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Create a custom generation config to customize settings, such as temperature,\n",
        "# response type, etc.\n",
        "# - https://googleapis.github.io/python-genai/index.html#typed-config\n",
        "MODEL_ID= 'gemini-2.5-flash-preview-05-20' # @param [\"gemini-2.5-flash-preview-05-20\", \"gemini-2.5-flash-05-20\", \"gemini-2.0-flash-001\", \"gemini-2.0-flash-lite-preview-02-05\", \"gemini-2.0-pro-exp-02-05\",\"gemini-2.0-flash-thinking-exp-01-21\", \"gemini-1.5-flash-002\", \"gemini-1.5-pro-002\", \"meta/llama-3.2-90b-vision-instruct-maas\", \"meta/llama-3.1-405b-instruct-maas\",\"meta/llama-3.1-70b-instruct-maas\",\"meta/llama-3.1-8b-instruct-maas\"]\n",
        "TEMPERATURE= 1 # @param {type:\"slider\", min:0, max:2, step:0.01}\n",
        "TOP_P = 0.95 # @param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "TOP_K = 40 # @param {type:\"slider\", min:1, max:40, step:1}\n",
        "MAX_OUTPUT_TOKENS = 8192 # @param {type:\"slider\", min:64, max:8192, step:64}\n",
        "RESPONSE_TYPE = 'text/plain' # @param [\"text/plain\", \"application/json\"]\n",
        "SYSTEM_INSTRUCTION = \"\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "CUSTOM_GENERATION_CONFIG = {\n",
        "    \"max_output_tokens\": MAX_OUTPUT_TOKENS,\n",
        "    \"temperature\": TEMPERATURE,\n",
        "    \"top_p\": TOP_P,\n",
        "    \"top_k\": TOP_K,\n",
        "    \"safety_settings\": CUSTOM_SAFETY_SETTINGS,\n",
        "    \"responseMimeType\": RESPONSE_TYPE,\n",
        "    \"system_instruction\": SYSTEM_INSTRUCTION\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBH7TuLZKpDX"
      },
      "source": [
        "## Initialize the Client Library\n",
        "We initialize the client by first determining whether or not to use Vertex AI by checking if \"PROJECT_ID\" is empty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0ddAN0DEdzo"
      },
      "source": [
        "## Initialize the GenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oazAo4rIV3st"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Initialize the client by first determining whether or not to use Vertex AI\n",
        "# by checking if \"PROJECT_ID\" is empty.\n",
        "if PROJECT_ID == \"\":\n",
        "  GOOGLE_API_KEY=userdata.get('AI_STUDIO_API_KEY')\n",
        "  client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "else:\n",
        "  client = genai.Client(project=PROJECT_ID, location=LOCATION, vertexai=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGCvqlItnhMt"
      },
      "source": [
        "# 2.0 - CALL THE MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "ckURdz7-V8om",
        "outputId": "3a5242b6-ceed-49db-b2c3-deff85108e0d"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What as an AI Agent?\"\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VvdYmbxKyce"
      },
      "source": [
        "## Examine Response Object\n",
        "\n",
        "**Sample Response:**\n",
        "```\n",
        "{\n",
        "  \"candidates\": [\n",
        "    {\n",
        "      \"content\": {\n",
        "        \"parts\": [\n",
        "          {\n",
        "            \"video_metadata\": null,\n",
        "            \"thought\": null,\n",
        "            ...\n",
        "            \"text\": \"The largest planet in our solar system is **Jupiter**.\"\n",
        "          }\n",
        "        ],\n",
        "        \"role\": \"model\"\n",
        "      },\n",
        "      \"citation_metadata\": {\n",
        "        \"citations\": [\n",
        "        ...\n",
        "        ]\n",
        "      },\n",
        "      ...\n",
        "    }\n",
        "  ],\n",
        "  \"create_time\": \"2025-06-11T16:07:05.332005Z\",\n",
        "  \"response_id\": \"qalJaOWhFNixgLUP1vHfwAE\",\n",
        "  \"model_version\": \"gemini-2.5-flash-preview-05-20\",\n",
        "  ...\n",
        "  \"usage_metadata\": {\n",
        "    \"cache_tokens_details\": null,\n",
        "    \"cached_content_token_count\": null,\n",
        "    \"candidates_token_count\": 219,\n",
        "    ...\n",
        "    \"prompt_token_count\": 19,\n",
        "    ...\n",
        "    \"thoughts_token_count\": 595,\n",
        "    ...\n",
        "    \"total_token_count\": 833,\n",
        "    \"traffic_type\": \"ON_DEMAND\"\n",
        "  },\n",
        "  \"automatic_function_calling_history\": [],\n",
        "  \"parsed\": null\n",
        "}\n",
        "```\n",
        "\n",
        "Note `usage_metadata` which includes token counts (useful when estimating costs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTushxh0ZGrm",
        "outputId": "f67d49d8-df3f-48cc-d99e-e23fcd841224"
      },
      "outputs": [],
      "source": [
        "print(response.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq_Anvz7L2P0"
      },
      "source": [
        "# 3.0 - FUNCTION CALLING\n",
        "\n",
        "Function Calling (or \"Tool Calling\") is most important capability at our disposal.\n",
        "\n",
        "Gemini can be instructed to format its output in such a way that the GenAI SDK can interpret as a request to call a function. The SDK can **automatically** execute the function and pass the results back to Gemini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxbRn7ZFMXUu"
      },
      "source": [
        "## A Sample \"Weather\" Function\n",
        "This function simulates an external API call by returning randomly-selected weather conditions for a given location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5ZrbuzBaeJu"
      },
      "outputs": [],
      "source": [
        "from google.genai.types import Tool, GoogleSearch, UrlContext, Content, Part\n",
        "\n",
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"Returns the current weather.\n",
        "\n",
        "    Args:\n",
        "      location: The city and state, e.g. San Francisco, CA as a string\n",
        "    \"\"\"\n",
        "    import random\n",
        "\n",
        "    weather_conditions = [\n",
        "        \"sunny\",\n",
        "        \"cloudy\",\n",
        "        \"rainy\",\n",
        "        \"windy\",\n",
        "        \"snowy\",\n",
        "        \"foggy\",\n",
        "        \"stormy\",\n",
        "        \"partly cloudy\",\n",
        "        \"drizzling\",\n",
        "        \"hailing\",\n",
        "        \"thunderstorm\",\n",
        "        \"overcast\",\n",
        "        \"clear sky\",\n",
        "        \"light rain\",\n",
        "        \"heavy rain\",\n",
        "        \"light snow\",\n",
        "        \"heavy snow\",\n",
        "        \"blizzard\",\n",
        "        \"hurricane\",\n",
        "        \"tornado\",\n",
        "    ]\n",
        "\n",
        "    conditions = random.choice(weather_conditions)\n",
        "\n",
        "    print(f\"DEBUG: get_current_weather() called.\\nLocation: {location}\\nWeather Conditions: {conditions}\\n\\n\\n\")\n",
        "    return conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEigeBuOMl_v"
      },
      "source": [
        "## Calling the Weather Function\n",
        "\n",
        "First, we define a Python list called `tools` that includes a reference to our function. The GenAI SDK uses [Python Metaprogramming](https://developer.ibm.com/tutorials/ba-metaprogramming-python/) to instrospect the function and convert it into a schema that Gemini has been trained to understand and \"invoke\".\n",
        "\n",
        "**Remember:** Gemini doesn't actually have the ability to call the function, it instead returns a message that the SDK interprets as a function call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "Egbr90tRcNYN",
        "outputId": "63394727-1d79-4ad0-ae0d-465f4f63d888"
      },
      "outputs": [],
      "source": [
        "tools = [get_current_weather]\n",
        "\n",
        "config = types.GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        system_instruction=\"Speak in rhyme\"\n",
        "    )\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='What is the weather like in Boston, MA?',\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8QWmJT7UL6S"
      },
      "source": [
        "### Examine Automatic Function Call Response\n",
        "\n",
        "The `automatic_function_calling_history` property in the `response` object contains a series of parts which include function calls:\n",
        "\n",
        "```\n",
        "    {\n",
        "      \"video_metadata\": null,\n",
        "      \"thought\": null,\n",
        "      \"inline_data\": null,\n",
        "      \"file_data\": null,\n",
        "      \"thought_signature\": null,\n",
        "      \"code_execution_result\": null,\n",
        "      \"executable_code\": null,\n",
        "      \"function_call\": {\n",
        "        \"id\": null,\n",
        "        \"args\": {\n",
        "          \"location\": \"Boston, MA\"\n",
        "        },\n",
        "        \"name\": \"get_current_weather\"\n",
        "      },\n",
        "      \"function_response\": null,\n",
        "      \"text\": null\n",
        "    }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp_0WUitVRWJ"
      },
      "source": [
        "### Print Function Call Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OHNzQ_4caoo",
        "outputId": "5bcfd2c0-bc52-47eb-9ceb-2143eeb59278"
      },
      "outputs": [],
      "source": [
        "for content in response.automatic_function_calling_history:\n",
        "  for part in content.parts:\n",
        "    if part.function_call:\n",
        "      print(part.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQLRJGN7Vgv3"
      },
      "source": [
        "## Manual Function Calling\n",
        "\n",
        "We use a custom config object that disables automatic function calls.\n",
        "\n",
        "Learn more about function calling [here](https://ai.google.dev/gemini-api/docs/function-calling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozr7227KdrjE"
      },
      "outputs": [],
      "source": [
        "config = types.GenerateContentConfig(\n",
        "          tools=[get_current_weather],\n",
        "          automatic_function_calling=types.AutomaticFunctionCallingConfig(\n",
        "              disable=True\n",
        "          )\n",
        "        )\n",
        "\n",
        "weather_query = 'What is the weather like in Boston, MA?'\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=weather_query,\n",
        "    config=config,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suUxbk6eV8TM"
      },
      "source": [
        "#### Locating the Function Call Response\n",
        "\n",
        "This time, the function call is in `response.function_calls`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab-YqkOQV8rn",
        "outputId": "dbf8f955-1e26-4cd9-f350-f2aeffa670cf"
      },
      "outputs": [],
      "source": [
        "print(f\"Function Calls:\\n{response.function_calls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43xrGN6qWuLa"
      },
      "source": [
        "### Manually Call the Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drQrRAAohLt5",
        "outputId": "c2b7323c-f836-491b-8147-15dcbfda3a3c"
      },
      "outputs": [],
      "source": [
        "fn_result_parts = []\n",
        "\n",
        "# Call every function\n",
        "for call in response.function_calls:\n",
        "  print(f\"Found Function Call in Response:\\n{call}\\n\")\n",
        "  fn_name = \"\"\n",
        "  fn_results = \"\"\n",
        "  if call.name:\n",
        "    fn = locals()[call.name]      # Retrieve function by name\n",
        "    fn_results = fn(**call.args)  # Call the Function\n",
        "    fn_name = call.name           # We'll use the function name later\n",
        "\n",
        "\n",
        "    # Wrap the function response into a Part and append it to the list of function results.\n",
        "    # Function call results must be preceded by the original function call \"Part\"\n",
        "    # Note that Part.from_function_response() requires the response\n",
        "    # to be in a dictionary. It can be somethign as simple as {\"result\": result}\n",
        "    print(f\"Function Results:\\n {fn_name}: {fn_results}\\n\")\n",
        "    fn_result_parts.append(call)\n",
        "    fn_result_parts.append(\n",
        "        Part.from_function_response(\n",
        "            name=fn_name,\n",
        "            response={\"result\":fn_results}\n",
        "            )\n",
        "        )\n",
        "\n",
        "# Print the output of calling that function\n",
        "print(f\"Function Results:{fn_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qvc6vde09Ot"
      },
      "outputs": [],
      "source": [
        "# Construct the function call results Content object\n",
        "fn_content = Content(\n",
        "    parts=fn_result_parts,\n",
        "    role=\"model\")\n",
        "\n",
        "# Append the function content into the previous response's content\n",
        "# to create a \"history\" (or \"memory\")\n",
        "history = [response.candidates[0].content, fn_content, \"Function Call Results have been provided\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3G-MDxXgBW"
      },
      "source": [
        "### Send Function Call Results to Model\n",
        "\n",
        "We append the function call results into the previous results and call the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "m8pfMKR_bf6u",
        "outputId": "92eb220c-05c5-450e-d7ff-240167ace76a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Invoke the model\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=history,\n",
        "    config=types.GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        automatic_function_calling=types.AutomaticFunctionCallingConfig(\n",
        "            disable=True\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "# print(response.model_dump_json(indent=2)) # Uncomment to debug\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vbAG2CU-CJJ"
      },
      "source": [
        "## Google Search Tool & URL Context\n",
        "The GenAI SDK includes special tools for Google Search and to download the contents of a website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "4bJp2ZQj-RAj",
        "outputId": "708ce9e6-d549-468f-a354-dae01f813069"
      },
      "outputs": [],
      "source": [
        "tools = [Tool(google_search=GoogleSearch()), Tool(url_context=UrlContext())]\n",
        "config = types.GenerateContentConfig(\n",
        "          tools=tools,\n",
        "        )\n",
        "\n",
        "prompt = \"Where can I buy pool furniture near San Jose, CA\"\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "LSZrhD22-xyu",
        "outputId": "76b16da0-e9c2-48d0-dff0-15c603f61bb1"
      },
      "outputs": [],
      "source": [
        "prompt = \"What are the headlines at https://news.smol.ai/\"\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIOvFcXl6a0q"
      },
      "source": [
        "# 4.0 - AGENTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn8T_kbNmnFp"
      },
      "source": [
        "## Workflow-style Agent: Using Google Search Retrieval Tool to Appraise Trading Cards\n",
        "\n",
        "This example uses function calling, Google search, structured output, and procedural code to demonstratea semi-agentic workflow that appraises the value of a collectible trading card by:\n",
        "1. Downloading a photo of the card\n",
        "2. Extracting text from the card\n",
        "3. Using the text to execute a Google Search and appraise the value\n",
        "4. Use the appraisal and extracted data to generate final output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gs-J-3zjwvug",
        "outputId": "cbea28e5-e106-4710-d861-047ad0e290ed"
      },
      "outputs": [],
      "source": [
        "# prompt: Display the image at this url: \"https://i.ebayimg.com/images/g/-64AAOSwBKhnEIQm/s-l1600.webp\"\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(url=\"https://i.ebayimg.com/images/g/-64AAOSwBKhnEIQm/s-l1600.webp\", width=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asv46SammoNq"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class PriceEstimate(BaseModel):\n",
        "    market_price: Optional[float] = None\n",
        "    low_price: Optional[float] = None\n",
        "    high_price: Optional[float] = None\n",
        "    average_price: Optional[float] = None\n",
        "    last_sold_price: Optional[float] = None\n",
        "    currency: str = \"USD\"\n",
        "\n",
        "\n",
        "class Card(BaseModel):\n",
        "    title: str = Field(description=\"Card Title\")\n",
        "    image_url: str = Field(description=\"Card Image URL as provided in the prompt\")\n",
        "    ocr_text: str = Field(description=\"Card OCR Text\")\n",
        "    card_set: str = Field(description=\"Card Set\")\n",
        "    game_category: str = Field(description=\"Card Game Category (e.g., Pokémon, Magic: The Gathering, Yu-Gi-Oh!, Topps, etc.)\")\n",
        "    grader_authority: str = Field(description=\"Card grader authority (e.g. BGS, PSA, SGC, etc.)\")\n",
        "    grade: str = Field(description=\"Card grade\")\n",
        "    variant: str = Field(description=\"Card variant (e.g. Holo, Shadowless, Ultra rare, Autograph)\")\n",
        "    language: str = Field(description=\"Card language (e.g. English, Japanese)\")\n",
        "    serial_number: str = Field(description=\"Card serial number\")\n",
        "    number: str = Field(description=\"Card number\")\n",
        "    price_estimate: PriceEstimate = Field(description=\"Card price estimate\")\n",
        "\n",
        "\n",
        "class AppraisalResponses(BaseModel):\n",
        "    extracted_card_response: types.GenerateContentResponse\n",
        "    appraisal_response: types.GenerateContentResponse\n",
        "    estimated_price_response: types.GenerateContentResponse\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "  evaluation: Card\n",
        "  responses: AppraisalResponses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WezLP1llmrDf"
      },
      "outputs": [],
      "source": [
        "extraction_system_instruction = \"\"\"\n",
        "You are tasked with extracting information from collectible trading cards.\n",
        "\n",
        "You will be provided with an image and a JSON schema.\n",
        "\n",
        "Examples of fields and their possible values include:\n",
        "\n",
        "card game (e.g., Pokémon, Magic: The Gathering, Yu-Gi-Oh!, Topps),\n",
        "set name,\n",
        "card title,\n",
        "grader (e.g. BGS, PSA, SGC, etc.),\n",
        "card grade,\n",
        "variant: (e.g. Holo, Shadowless, Ultra rare, Autograph),\n",
        "language: (e.g. English, Japanese),\n",
        "Serial Number,\n",
        "Card Number\n",
        "\"\"\"\n",
        "\n",
        "appraisal_system_instruction = \"\"\"\n",
        "You are tasked with evaluating information from collectible trading cards\n",
        "and estimating their current market value.\n",
        "\n",
        "You will be provided with a JSON document containing the extracted data from a card image.\n",
        "\n",
        "Use the data to compose Google search queries to estimate the current market value of the card.\n",
        "\n",
        "Use the Google Search Tool to search for details about these trading cards\n",
        "to estimate its current market value as accurately as possible.\n",
        "Base your valuation on the most recent verifiable sales and market trends.\n",
        "\n",
        "Consider the following factors:\n",
        "card game (e.g., Pokémon, Magic: The Gathering, Yu-Gi-Oh!, Topps),\n",
        "set name, card title, grader (e.g. BGS, PSA, SGC, etc.), card grade,\n",
        "variant: (e.g. Holo, Shadowless, Ultra rare, Autograph),\n",
        "language: (e.g. English, Japanese), Serial Number, Card Number,\n",
        "recent sales data (e.g., eBay, TCGPlayer, Heritage Auctions),\n",
        "demand trends, and historical price fluctuations.\n",
        "\n",
        "If the card has notable errors, misprints, or special variations,\n",
        "adjust the estimate accordingly.\n",
        "\n",
        "Provide a detailed appraisal based on your searches and conclude your appraisal with the following data points:\n",
        "   * market_price: The current market price of the card.\n",
        "   * low_price: The lowest price you found\n",
        "   * high_price: The highest price you found\n",
        "   * average_price: The average price you found\n",
        "   * last_sold_price: The price of the last sold card\n",
        "   * currency: The currency of the price (e.g. USD)\n",
        "\"\"\"\n",
        "\n",
        "price_estimate_system_instruction = \"\"\"\n",
        "Use the provided trading card appraisal and extract the values for the following fields:\n",
        "   * market_price: The current market price of the card.\n",
        "   * low_price: The lowest price you found\n",
        "   * high_price: The highest price you found\n",
        "   * average_price: The average price you found\n",
        "   * last_sold_price: The price of the last sold card\n",
        "   * currency: The currency of the price (e.g. USD)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCXOif8pmu8J"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import Image as ShowImage\n",
        "import requests\n",
        "import io\n",
        "from google.genai import types\n",
        "\n",
        "def get_card_image(card_url) -> bytes:\n",
        "  \"\"\"Gets the card image from the URL and converts it to JPEG.\n",
        "\n",
        "  Args:\n",
        "    card_url: The URL of the card image.\n",
        "\n",
        "  Returns:\n",
        "    The card image as a JPEG byte string.\n",
        "  \"\"\"\n",
        "  response = requests.get(card_url, stream=True, allow_redirects=True)\n",
        "  response.raise_for_status()  # Raise an exception for bad responses (4xx or 5xx)\n",
        "  image = Image.open(io.BytesIO(response.content))\n",
        "\n",
        "  # Convert the image to RGB mode if it's not already\n",
        "  if image.mode != 'RGB':\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "  # Save the image to a byte buffer in JPEG format\n",
        "  with io.BytesIO() as output:\n",
        "    image.save(output, format=\"JPEG\")\n",
        "    jpeg_data = output.getvalue()\n",
        "\n",
        "  return jpeg_data\n",
        "\n",
        "\n",
        "def extract_card_data(image: bytes, image_url) -> types.GenerateContentResponse:\n",
        "  image_part = types.Part.from_bytes(\n",
        "        data=image,\n",
        "        mime_type=\"image/jpeg\"\n",
        "      )\n",
        "  # Create a multi-part prompt\n",
        "  prompt = [\n",
        "      image_part,\n",
        "      f\"Extract the above content per the system instructions. The image URL is: {image_url}\"\n",
        "  ]\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model=MODEL_ID,\n",
        "      contents=prompt,\n",
        "      config=types.GenerateContentConfig(\n",
        "          system_instruction=extraction_system_instruction,\n",
        "          response_mime_type='application/json',\n",
        "          response_schema=Card,\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  return response\n",
        "\n",
        "def appraise_card(card: Card) -> types.GenerateContentResponse:\n",
        "    response = client.models.generate_content(\n",
        "      model=MODEL_ID,\n",
        "      contents=card.model_dump_json(indent=2),\n",
        "      config=types.GenerateContentConfig(\n",
        "          system_instruction=appraisal_system_instruction,\n",
        "          tools=[types.Tool(\n",
        "            google_search=types.GoogleSearchRetrieval\n",
        "        )]\n",
        "      )\n",
        "    )\n",
        "\n",
        "    return response\n",
        "\n",
        "def get_price_estimate(appraisal: str) -> PriceEstimate:\n",
        "    response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=appraisal,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=price_estimate_system_instruction,\n",
        "        response_mime_type='application/json',\n",
        "        response_schema=PriceEstimate,\n",
        "      ),\n",
        "    )\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_card(image: bytes, image_url) -> tuple[Card, AppraisalResponses]:\n",
        "    # Step 1: OCR the Card and extract the data\n",
        "    extracted_card = extract_card_data(image, image_url)\n",
        "\n",
        "    card = extracted_card.parsed # Returns Pydantic model instance\n",
        "\n",
        "    # Step 2: Appraise the card (Markdown Format)\n",
        "    appraisal = appraise_card(card)\n",
        "\n",
        "    # Step 3: Convert the appraisal into a structured object\n",
        "    estimated_price = get_price_estimate(appraisal.text)\n",
        "    card.price_estimate = estimated_price.parsed # Returns Pydantic model instance\n",
        "\n",
        "    responses = AppraisalResponses(extracted_card_response=extracted_card,\n",
        "                                   appraisal_response=appraisal,\n",
        "                                   estimated_price_response=estimated_price)\n",
        "    return card, responses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cABjVD1SmxR-",
        "outputId": "81c817f5-0da0-410e-ed83-b67bacc2ea52"
      },
      "outputs": [],
      "source": [
        "card_image_url = \"https://i.ebayimg.com/images/g/-64AAOSwBKhnEIQm/s-l1600.webp\"\n",
        "image = get_card_image(card_image_url)\n",
        "\n",
        "extracted_card = extract_card_data(image, card_image_url)\n",
        "\n",
        "card = extracted_card.parsed\n",
        "appraisal = appraise_card(card)\n",
        "estimate = get_price_estimate(appraisal.text)\n",
        "card.price_estimate = estimate.parsed\n",
        "\n",
        "print(appraisal.text)\n",
        "print(\"======\")\n",
        "print(estimate.parsed.model_dump_json(indent=2))\n",
        "print(\"======\")\n",
        "print(card.model_dump_json(indent=2))\n",
        "print(\"======\")\n",
        "ShowImage(image, width=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E35UM8_Dm1E_"
      },
      "source": [
        "# A Basic Research Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVHF7NTVt3mB"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Part 1: Setup and Dependencies\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import google.genai as genai\n",
        "from google.genai.types import Tool, Content, Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA9_g7VEaZLZ"
      },
      "outputs": [],
      "source": [
        "research_system_prompt = \"\"\"\n",
        "You are an Exploratory Inquiry Agent.\n",
        "\n",
        "**Your Task:**\n",
        "In each turn, you will perform two actions in your response:\n",
        "1.  **Synthesize:** Based on the current query and history, use your tools to research and then provide a clear synthesis of your findings.\n",
        "2.  **Generate Questions:** After your synthesis, provide a list of 3-5 new follow-up questions to guide the next turn of research.\n",
        "\n",
        "**Citation Format:**\n",
        "When you state a fact from a source found via `Google Search`, you MUST cite it immediately using this exact markdown format: `[Source: Title of Webpage](URI)`\n",
        "For example: The sky appears blue due to Rayleigh scattering [Source: Why Is the Sky Blue?](https://spaceplace.nasa.gov/blue-sky/en/).\n",
        "\n",
        "**Response Format:**\n",
        "You MUST structure your response EXACTLY as follows:\n",
        "\n",
        "<synthesis>\n",
        "[Your detailed synthesis of the information you found in this turn goes here. Every fact must include an inline citation using the specified `Citation Format`.]\n",
        "</synthesis>\n",
        "\n",
        "<questions>\n",
        "1. [First follow-up question]\n",
        "2. [Second follow-up question]\n",
        "...\n",
        "</questions>\n",
        "\n",
        "If you believe the research is complete, write \"FINISHED\" inside the <questions> tag.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "final_report_prompt = \"\"\"\n",
        "You are now a Research Report Synthesizer. Your sole purpose is to transform the provided conversation history into a single, polished, and comprehensive final report.\n",
        "\n",
        "**Core Instructions:**\n",
        "\n",
        "1.  **Cease Research:** You must not call any tools. Your task is to write based *only* on the information already present in the conversation history.\n",
        "2.  **Synthesize, Do Not Recite:** Consolidate all related facts from across the entire history into cohesive, thematic sections. Do not simply summarize turn-by-turn.\n",
        "3.  **Cite Rigorously:** Every piece of information taken from a source must be attributed with its source using the markdown format: `[Source: Title of Webpage](URI)`. You must find these citations from the provided history.\n",
        "4.  **Structure is Mandatory:** You must format your output in Markdown format *exactly* according to the structure defined below.\n",
        "\n",
        "**Final Report Structure:**\n",
        "\n",
        "### **1. Executive Summary**\n",
        "...\n",
        "### **2. Introduction**\n",
        "...\n",
        "### **3. Detailed Findings**\n",
        "...For each section:\n",
        "* ...\n",
        "* Ensure every claim derived from a source is followed by its inline citation: `[Source: Title](URI)`.\n",
        "\n",
        "### **4. Conclusion**\n",
        "...\n",
        "### **5. Sources**\n",
        "\n",
        "Create a \"Sources\" section with a bulleted list of all unique sources used to build this report.\n",
        "* Each source must be formatted as: `* **[Title of Webpage](URI)**`\n",
        "* The list should be de-duplicated.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "def research_agent(query: str, max_iterations: int = 8):\n",
        "    \"\"\"\n",
        "    An agent that performs research using Google Search and URL fetching,\n",
        "    synthesizes findings, and generates follow-up questions in a loop.\n",
        "\n",
        "    Args:\n",
        "        query: The initial research query.\n",
        "        max_iterations: The maximum number of turns the agent will perform.\n",
        "\n",
        "    Returns:\n",
        "        The final research report generated after the research is complete.\n",
        "    \"\"\"\n",
        "    # Define the tools available to the agent using Google Search and URL Context\n",
        "    tool_belt = [Tool(google_search=types.GoogleSearch()), Tool(url_context=UrlContext())]\n",
        "\n",
        "    # Configure the model for content generation with the specified tools and system instruction\n",
        "    config = types.GenerateContentConfig(\n",
        "        tools=tool_belt,\n",
        "        system_instruction=research_system_prompt,  # Use the dedicated research prompt\n",
        "        temperature=0.3  # Lower temperature for more focused research\n",
        "    )\n",
        "\n",
        "    # Initialize the conversation memory with the system prompt and the user's initial query\n",
        "    memory = [Content(parts=[Part.from_text(text=query)], role='user')]\n",
        "\n",
        "    print(f\"================== Agent Starting for query: '{query}' ==================\\n\")\n",
        "\n",
        "    # Start the research loop\n",
        "    for i in range(max_iterations):\n",
        "        print(f\"\\n================== Turn {i + 1} ==================\\n\")\n",
        "\n",
        "        # Generate the next turn's content based on the memory and config\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-preview-05-20\", # Use a suitable model for this task\n",
        "            contents=memory,\n",
        "            config=config\n",
        "        )\n",
        "        message = response.text\n",
        "\n",
        "        # Parse the response to extract synthesis and follow-up questions\n",
        "        synthesis_match = re.search(r'<synthesis>(.*?)</synthesis>', message, re.DOTALL)\n",
        "        questions_match = re.search(r'<questions>(.*?)</questions>', message, re.DOTALL)\n",
        "\n",
        "        # Extract grounding metadata (from Google Search tool) if available\n",
        "        grounding_metadata = response.candidates[0].grounding_metadata.model_dump_json(indent=2) if response.candidates[0].grounding_metadata else \"No grounding chunks provided.\"\n",
        "\n",
        "        # Extract synthesis and questions, handling cases where tags are not found\n",
        "        synthesis = synthesis_match.group(1).strip() if synthesis_match else \"No synthesis provided.\"\n",
        "        questions = questions_match.group(1).strip() if questions_match else \"FINISHED\" # Assume finished if no questions tag\n",
        "\n",
        "        # Generate a brief summary of the current turn's findings and next steps\n",
        "        research_summary = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash-lite\", # Use a lighter model for summarization\n",
        "            contents=f\"Briefly summarize the following research in just a few words formatted in Markdown and introducing newlines every 10 words. Frame it as 'I have learned (summary of contents of '<synthesis/>' tags) and will research (summary of content og <questions/> tag)'\\n <research>{message}</research>\"\n",
        "        )\n",
        "\n",
        "        print(research_summary.text)\n",
        "        print(f\"Follow-up Questions: {questions}\")\n",
        "\n",
        "        # Check if the research is complete based on the model's output\n",
        "        if \"FINISHED\" in questions:\n",
        "            print(\"\\n>>>>> Model has determined research is complete.\")\n",
        "            # Add the final synthesis to the memory before generating the report\n",
        "            memory.append(response.candidates[0].content)\n",
        "            break\n",
        "\n",
        "        # Append the full model response and grounding metadata to memory for context in the next turn\n",
        "        memory.append(response.candidates[0].content)\n",
        "        memory.append(Content(parts=[\n",
        "                                      Part.from_text(text=f\"<grounding_metadata>\\n{grounding_metadata}\\n</grounding_metadata>\"),\n",
        "                                      Part.from_text(text=f\"I will now research these follow-up questions: {questions}\")\n",
        "                                      ], role=\"model\"))\n",
        "        # End of loop\n",
        "\n",
        "    # --- Final Report Generation ---\n",
        "    print(\"\\n================== Research Phase Complete. Generating Final Report... ==================\\n\")\n",
        "\n",
        "    # Configure the model specifically for generating the final report\n",
        "    report_config = types.GenerateContentConfig(\n",
        "        system_instruction=final_report_prompt, # Use the dedicated report prompt\n",
        "        temperature=0 # Zero temperature for a deterministic and structured report\n",
        "    )\n",
        "\n",
        "    # Generate the final report based on the complete conversation history\n",
        "    final_report_response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-pro-preview-05-06\", # Use a capable model for report generation\n",
        "        contents=memory,\n",
        "        config=report_config\n",
        "    )\n",
        "    final_report = final_report_response.text\n",
        "    # print(final_report) # Uncomment for debugging\n",
        "    return final_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcEbImazdaUx",
        "outputId": "c8c5fb16-bb9e-4d58-ca4b-04103ce2bd9b"
      },
      "outputs": [],
      "source": [
        "max_iterations = 2\n",
        "final_report = research_agent(\"Research the various techniques for architecting GenAI agents.\", max_iterations=max_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "53xXN72ldfTF",
        "outputId": "3e4fe306-561d-474b-d50f-5ed3f4c8ac67"
      },
      "outputs": [],
      "source": [
        "Markdown(final_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLdYcq7WJg6w"
      },
      "source": [
        "## SAMPLE RESEARCH REPORT\n",
        "\n",
        "### **1. Executive Summary**\n",
        "\n",
        "This report synthesizes research on the architecture of Generative AI (GenAI) agents. GenAI agents are sophisticated systems leveraging Large Language Models (LLMs) to autonomously perform complex tasks by understanding context, reasoning, planning, and interacting with their environment through tools and APIs. Effective agent architecture involves a modular design, robust orchestration, and distinct perception and action modules. Key design patterns include the perception-reasoning-action loop, tool use, planning, reflection, multi-agent collaboration, human-in-the-loop, and guardrails. Various frameworks like LangChain, LlamaIndex, AutoGen, and CrewAI facilitate development.\n",
        "\n",
        "Implementing multi-agent collaboration presents challenges such as scalability, coordination overhead, and security, which are addressed through specialized agents, defined protocols, and robust frameworks. The choice of LLM significantly impacts an agent's capabilities, performance, and architectural adaptations. Evaluating GenAI agents requires a combination of automated metrics and human-in-the-loop testing, focusing on aspects like accuracy, robustness, bias, and coherence. Ethical considerations, particularly bias propagation, misinformation, and privacy, are paramount, necessitating strategies like diverse datasets, algorithmic debiasing, transparency, and human oversight.\n",
        "\n",
        "### **2. Introduction**\n",
        "\n",
        "Generative AI (GenAI) agents represent a significant advancement in artificial intelligence, moving beyond simple language generation to systems capable of autonomous action and complex problem-solving. These agents are designed to understand real-world goals, interpret context, formulate plans, and execute actions by interacting with various digital tools and APIs [Source: beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEQ6puVsP7gH6FnAeh9mKDlRb6BKpyod2DKpjI8kFsNAwI6f2KKmBs-znCkMLuEMwQIhca-6geEoPZlNrwj1Oe6KLOi2liqQbMDVRGuc_fwbrIOEnFouuCy-WdO64mjtIEV_bRnEdbJ2ng5WOu1BuyVBI6pjRvmBjKwhxqsEbEJaJA=). Architecting these agents involves a multi-faceted approach, considering their core components, the design patterns that enable their autonomy, the frameworks that support their development, and the critical challenges related to collaboration, evaluation, and ethics. This report details these various facets to provide a comprehensive overview of techniques for architecting GenAI agents.\n",
        "\n",
        "### **3. Detailed Findings**\n",
        "\n",
        "**3.1 Core Components of GenAI Agents**\n",
        "\n",
        "The architecture of GenAI agents is typically modular and goal-driven, featuring several key components:\n",
        "\n",
        "*   **Modular Design and Orchestration:** Agents are often built with an orchestration layer that coordinates different modules, enabling them to transform workflows and automate tasks [Source: beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEQ6puVsP7gH6FnAeh9mKDlRb6BKpyod2DKpjI8kFsNAwI6f2KKmBs-znCkMLuEMwQIhca-6geEoPZlNrwj1Oe6KLOi2liqQbMDVRGuc_fwbrIOEnFouuCy-WdO64mjtIEV_bRnEdbJ2ng5WOu1BuyVBI6pjRvmBjKwhxqsEbEJaJA=). Building small, focused agents that interact is often more effective than a single monolithic agent, enhancing modularity, maintainability, and scalability [Source: amazon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXG4ZgjexrCnT0w6Ap1kFkD4VX7TQm-NqHYNyt0AxvEz1w02_DmjeXdPmOAlXFycH056zqy1mLd9DY-FSkVu4QqtiG-YhesCMWcWa2EmSg4p50_ENeYznXw2pRqIOB2M3hmVXhZbicwSdObi1dmYPHjHZC8FJ4SdV0IB8VipQJ5ycptQyS-KqIkWfSX8dKTc5eat1wo66tr6KklL8seVUnQO7CHe9OdxytPp_9L_ZwxNDrQIyQICMHNLPLVqe3oJ_7JIA7QPMQsmYIKV).\n",
        "*   **Perception and Action Modules:** Perception modules gather information from the digital world (APIs, databases, web scraping), grounding decisions in real data. Action modules allow agents to influence their environment using tools like RPA software, APIs, and SDKs [Source: beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEQ6puVsP7gH6FnAeh9mKDlRb6BKpyod2DKpjI8kFsNAwI6f2KKmBs-znCkMLuEMwQIhca-6geEoPZlNrwj1Oe6KLOi2liqQbMDVRGuc_fwbrIOEnFouuCy-WdO64mjtIEV_bRnEdbJ2ng5WOu1BuyVBI6pjRvmBjKwhxqsEbEJaJA=).\n",
        "*   **Memory and Knowledge Bases:** Agents require memory to learn from past experiences. A knowledge base acts as long-term memory, storing domain-specific data to improve decision-making by identifying patterns and connections [Source: beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEQ6puVsP7gH6FnAeh9mKDlRb6BKpyod2DKpjI8kFsNAwI6f2KKmBs-znCkMLuEMwQIhca-6geEoPZlNrwj1Oe6KLOi2liqQbMDVRGuc_fwbrIOEnFouuCy-WdO64mjtIEV_bRnEdbJ2ng5WOu1BuyVBI6pjRvmBjKwhxqsEbEJaJA=). This can include memory-augmented context windows to handle information exceeding an LLM's token limit [Source: valanor.co](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGCFFdlr8272YIWiRyszv645ciIGO4mokMK5VUJXONZqrcQz4B1R8Vj7spByqr5MgcZko_MzQRBTadCGGUZCML-pLwH1V1s9gnSCNPIp1mVyNakFCjPVjHA4Qf-ULykFv83yWhP3FZhrQFPiqc=).\n",
        "*   **Integration with LLMs:** LLMs are central, enabling agents to understand and generate human language, interpret queries, extract information, and maintain coherent conversations. They provide contextual awareness and are crucial for natural language processing (NLP) [Source: dsstream.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXG78-3aCiGyn5dk7kBVfnmX0MfU1GXkdUYeQaucJq-LrAvI9ihGENQIpM1dE6Ogbp6X-3csZjMhzuqcElPYw5C3htq98Y6pQMoM5ByB8cFJpO-DnXctovGcBzz4V_7LmQ_dR2yyyOawqxAo9kNy-MbOfSOMDNv9UiqP0zSssivLoNToJCKWj1fuP42Myeh_MDEwZxuguufTJBYFzBkX), [Source: leewayhertz.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEs3TEfEeGPyeDj_1ftEQgmAbhODIcO8XAyiTAi6lK5SwhYfJEV8YcCtkwwfE23XTpWnrU9CsUBYpUZOcW0-xrGt3ei1UuN7QwVX79u3zOh9Rl8d-gHleZmtkG189sDbnirzSK6TU33wIxpw4BYhtCQ).\n",
        "\n",
        "**3.2 Key Design Patterns for GenAI Agents**\n",
        "\n",
        "Several design patterns enhance the capabilities and autonomy of GenAI agents:\n",
        "\n",
        "*   **Perception, Reasoning, Action Loop:** The fundamental cycle where an agent processes data (perception), analyzes inputs to choose actions (reasoning), and executes tasks (action) [Source: valanor.co](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGCFFdlr8272YIWiRyszv645ciIGO4mokMK5VUJXONZqrcQz4B1R8Vj7spByqr5MgcZko_MzQRBTadCGGUZCML-pLwH1V1s9gnSCNPIp1mVyNakFCjPVjHA4Qf-ULykFv83yWhP3FZhrQFPiqc=).\n",
        "*   **Tool Use:** Allows LLMs to interact with external tools and resources, significantly broadening their problem-solving capabilities [Source: analyticsvidhya.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFXODLyZ4Q0D7PjpnYoSpXCj704ZddZOOADYbORwVSFiVGN5o20sfSk-3Ljuz1uSnoHGoeaqwgU-kfS2kH1w76NSOMLjR0ZkBPjWhi47_9iLVc4NR_ZH8-KIv8y3sZznkzE1uJJmsLc0CHRh-LrDTMS8DjxOngL9Od2-aU_aUjb1A==).\n",
        "*   **Planning:** Enables an LLM to decompose complex tasks into smaller, manageable components [Source: analyticsvidhya.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFXODLyZ4Q0D7PjpnYoSpXCj704ZddZOOADYbORwVSFiVGN5o20sfSk-3Ljuz1uSnoHGoeaqwgU-kfS2kH1w76NSOMLjR0ZkBPjWhi47_9iLVc4NR_ZH8-KIv8y3sZznkzE1uJJmsLc0CHRh-LrDTMS8DjxOngL9Od2-aU_aUjb1A==).\n",
        "*   **Reflection/Self-Correction:** Improves an AI's ability to evaluate and refine its outputs, mimicking human iterative problem-solving [Source: mongodb.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF7ed62gl7MOVhqwRGUhClOBjk0_z5Vt1H2fLjc8_5Ry46eY-Z2l8sbh6NW9CrqDA3Gku1Xb141ZgOeCvPumbz9z77UuGKFpT-8sKYeGJCs158zwhpTwpS5tA1bFIoKI_Qkbuj3i_sNzmzRRLx4kKCs6gVfYPclquxqBsD2gWKHc_Brv24SBM8uCCyq), [Source: analyticsvidhya.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFXODLyZ4Q0D7PjpnYoSpXCj704ZddZOOADYbORwVSFiVGN5o20sfSk-3Ljuz1uSnoHGoeaqwgU-kfS2kH1w76NSOMLjR0ZkBPjWhi47_9iLVc4NR_ZH8-KIv8y3sZznkzE1uJJmsLc0CHRh-LrDTMS8DjxOngL9Od2-aU_aUjb1A==).\n",
        "*   **Multi-Agent Collaboration:** Involves multiple specialized agents working together, communicating, and coordinating to accomplish complex tasks [Source: mongodb.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF7ed62gl7MOVhqwRGUhClOBjk0_z5Vt1H2fLjc8_5Ry46eY-Z2l8sbh6NW9CrqDA3Gku1Xb141ZgOeCvPumbz9z77UuGKFpT-8sKYeGJCs158zwhpTwpS5tA1bFIoKI_Qkbuj3i_sNzmzRRLx4kKCs6gVfYPclquxqBsD2gWKHc_Brv24SBM8uCCyq), [Source: analyticsvidhya.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFXODLyZ4Q0D7PjpnYoSpXCj704ZddZOOADYbORwVSFiVGN5o20sfSk-3Ljuz1uSnoHGoeaqwgU-kfS2kH1w76NSOMLjR0ZkBPjWhi47_9iLVc4NR_ZH8-KIv8y3sZznkzE1uJJmsLc0CHRh-LrDTMS8DjxOngL9Od2-aU_aUjb1A==), [Source: valanor.co](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGCFFdlr8272YIWiRyszv645ciIGO4mokMK5VUJXONZqrcQz4B1R8Vj7spByqr5MgcZko_MzQRBTadCGGUZCML-pLwH1V1s9gnSCNPIp1mVyNakFCjPVjHA4Qf-ULykFv83yWhP3FZhrQFPiqc=), [Source: microsoft.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEK8QygjQJ_MFFNUoW2TfEBx2q_BA_RMA-pCoqIggvwUrjKrO8dv85UD9wy-C_jZ3DYEGtLv6x-Y5-3wvRLjutXPJoRLLz6ctmbNsJl-yz8Tm8hAxDMr0cymEdTNC13r6vRTOgofObUD9l0vujU9Hby_kMJ3M9XBDJCrX-dnfa7uopr9Tkc6Ee-cupQHyZ7aik6rEEswTHyYLi7e98J_aiZTiHbECIxSnkq7OLJqKLWBy59TQ==). This can include patterns like group chat, hand-off, and collaborative filtering [Source: microsoft.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEK8QygjQJ_MFFNUoW2TfEBx2q_BA_RMA-pCoqIggvwUrjKrO8dv85UD9wy-C_jZ3DYEGtLv6x-Y5-3wvRLjutXPJoRLLz6ctmbNsJl-yz8Tm8hAxDMr0cymEdTNC13r6vRTOgofObUD9l0vujU9Hby_kMJ3M9XBDJCrX-dnfa7uopr9Tkc6Ee-cupQHyZ7aik6rEEswTHyYLi7e98J_aiZTiHbECIxSnkq7OLJqKLWBy59TQ==).\n",
        "*   **Human-in-the-Loop (HITL):** Integrating human oversight and intervention to enhance reliability [Source: mongodb.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF7ed62gl7MOVhqwRGUhClOBjk0_z5Vt1H2fLjc8_5Ry46eY-Z2l8sbh6NW9CrqDA3Gku1Xb141ZgOeCvPumbz9z77UuGKFpT-8sKYeGJCs158zwhpTwpS5tA1bFIoKI_Qkbuj3i_sNzmzRRLx4kKCs6gVfYPclquxqBsD2gWKHc_Brv24SBM8uCCyq), [Source: microsoft.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEK8QygjQJ_MFFNUoW2TfEBx2q_BA_RMA-pCoqIggvwUrjKrO8dv85UD9wy-C_jZ3DYEGtLv6x-Y5-3wvRLjutXPJoRLLz6ctmbNsJl-yz8Tm8hAxDMr0cymEdTNC13r6vRTOgofObUD9l0vujU9Hby_kMJ3M9XBDJCrX-dnfa7uopr9Tkc6Ee-cupQHyZ7aik6rEEswTHyYLi7e98J_aiZTiHbECIxSnkq7OLJqKLWBy59TQ==).\n",
        "*   **Guardrails:** Implementing safety layers to filter, validate, or block outputs, reducing risks in sensitive tasks [Source: valanor.co](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGCFFdlr8272YIWiRyszv645ciIGO4mokMK5VUJXONZqrcQz4B1R8Vj7spByqr5MgcZko_MzQRBTadCGGUZCML-pLwH1V1s9gnSCNPIp1mVyNakFCjPVjHA4Qf-ULykFv83yWhP3FZhrQFPiqc=).\n",
        "\n",
        "**3.3 Frameworks for Developing GenAI Agents**\n",
        "\n",
        "Several open-source frameworks streamline GenAI agent development:\n",
        "\n",
        "*   **LangChain:** A popular, comprehensive ecosystem for building LLM-powered applications, offering modular components, chains, agents, and memory systems [Source: ibm.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHosrTEYdikzOGEDhOr48O82VcrUSK6uJBSUZ_Fw33Mt26nJj5dDU3U4qXYbTCq2U6w3Uazc_JEOikBzUAGbQbsnxR_83ieYfsnV2VwsJyFGXiVsSRAhmYGOfIaYHVgPkermw68u-fIaCrYGynBJBjzIB7lKb4=), [Source: dev.to](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH1O8_mdujAMWlDpiiIEOjILXJoip2RF8HzBZ-_Ds7-qegs20rqZbIqSWqlv4lib_kJKZtDiQiZ4xKaj2TShJtHHdIvuGvvySaX6POhTbeS1IYF6AFdKY-p194OY27bizOGknyeFs-_zFQOClGQ5yVChWCrnIvc2qhusjg1iKDFqg4eiTdApCaFxm7ibTOPk_q5), [Source: brightdata.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHdSe3DR5Wy90p1uZBX-zly8tJY5e1WNvGyCJKbI2lFoH2waKzo9D5CLfqZ9mnu_I_pTD1MTNR8qJWBa7jrr-8D9ytYSKhUSvPvrTmK0EKOiO9Ih87SJunfDZiIlex2cEQ9JhW6AGL_uVJC2t4yDmHGkX4=). It excels in modular design and memory management [Source: ardor.cloud](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEebd8yyfTSODps9IdpHaWDdHpZIHd_I72rxvv4uADFtPwa2XP-VfdaTjn6A2hTElrexHfj28DjRJLnUQF-FSGxD-TfuTBh7sy3v9YG-GaLSuxkJ8OyNiE-9OvYOKWfrSq-50KZdqLjRqmZAg8IDiFnUL5z6CB9763snw==).\n",
        "*   **LangGraph:** An extension of LangChain for building stateful, multi-actor applications with LLMs, enabling cyclical graphs and precise control for complex workflows [Source: dev.to](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH1O8_mdujAMWlDpiiIEOjILXJoip2RF8HzBZ-_Ds7-qegs20rqZbIqSWqlv4lib_kJKZtDiQiZ4xKaj2TShJtHHdIvuGvvySaX6POhTbeS1IYF6AFdKY-p194OY27bizOGknyeFs-_zFQOClGQ5yVChWCrnIvc2qhusjg1iKDFqg4eiTdApCaFxm7ibTOPk_q5), [Source: salesforce.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEq5qh5QID-3VSv4v4MW2F0AZFQW5SckUenSbHkrJNM1VCD_BVSyQhHON7-UTWjR-HS3YhV-cic5sRRggTpg12X0dKF056iPF_xqspaj9Py7sroxZlmi9Dco6wKIIOH2gTGgjQfyxJ1ibnHkJENKaFPA4iXAtEhk9c_16UKAHXV), [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=), [Source: langfuse.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGk4fIxVvWaS_jtBZliIhGlrCaRyc_cyys3KjjRTXnvhtbs0Tvr6zI26PC-M4kc2bTs78vDo_AUdKWx_GvAqXS21eWyZfsLaxZ1Ou-ZFVBGagIWlu75SIMOjKkyzabwMP64lWphPbcgzri8N_u9AwXsTu8=).\n",
        "*   **LlamaIndex:** An open-source data orchestration framework for GenAI and agentic AI, providing prepackaged agents and tools, excelling in retrieval-centric applications [Source: ibm.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHosrTEYdikzOGEDhOr48O82VcrUSK6uJBSUZ_Fw33Mt26nJj5dDU3U4qXYbTCq2U6w3Uazc_JEOikBzUAGbQbsnxR_83ieYfsnV2VwsJyFGXiVsSRAhmYGOfIaYHVgPkermw68u-fIaCrYGynBJBjzIB7lKb4=), [Source: dev.to](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH1O8_mdujAMWlDpiiIEOjILXJoip2RF8HzBZ-_Ds7-qegs20rqZbIqSWqlv4lib_kJKZtDiQiZ4xKaj2TShJtHHdIvuGvvySaX6POhTbeS1IYF6AFdKY-p194OY27bizOGknyeFs-_zFQOClGQ5yVChWCrnIvc2qhusjg1iKDFqg4eiTdApCaFxm7ibTOPk_q5), [Source: brightdata.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHdSe3DR5Wy90p1uZBX-zly8tJY5e1WNvGyCJKbI2lFoH2waKzo9D5CLfqZ9mnu_I_pTD1MTNR8qJWBa7jrr-8D9ytYSKhUSvPvrTmK0EKOiO9Ih87SJunfDZiIlex2cEQ9JhW6AGL_uVJC2t4yDmHGkX4=). It can be combined with CrewAI for sophisticated research flows [Source: ionio.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHP91kYhQCEpDG3jOrSyxauDf9sXWfxG60qBSWCkCQeo75W9ErU_T3eqXtXGn-o5YRZfHDqW-2OET6rYn4Cwe73GWvpGt4FyougReEUVZVlcJeOV7oOMv5DF5TdyMUyswNRGgmK3YA9TX8rWBGm29nt84xQQfK1HB5GeoatjTyHOpUVqzOOmEDek3R9AEp-S2g=).\n",
        "*   **AutoGen:** A Microsoft framework for creating multi-agent AI applications, supporting scalable, distributed agent networks and treating workflows as conversations [Source: ibm.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHosrTEYdikzOGEDhOr48O82VcrUSK6uJBSUZ_Fw33Mt26nJj5dDU3U4qXYbTCq2U6w3Uazc_JEOikBzUAGbQbsnxR_83ieYfsnV2VwsJyFGXiVsSRAhmYGOfIaYHVgPkermw68u-fIaCrYGynBJBjzIB7lKb4=), [Source: brightdata.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHdSe3DR5Wy90p1uZBX-zly8tJY5e1WNvGyCJKbI2lFoH2waKzo9D5CLfqZ9mnu_I_pTD1MTNR8qJWBa7jrr-8D9ytYSKhUSvPvrTmK0EKOiO9Ih87SJunfDZiIlex2cEQ9JhW6AGL_uVJC2t4yDmHGkX4=), [Source: ionio.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHP91kYhQCEpDG3jOrSyxauDf9sXWfxG60qBSWCkCQeo75W9ErU_T3eqXtXGn-o5YRZfHDqW-2OET6rYn4Cwe73GWvpGt4FyougReEUVZVlcJeOV7oOMv5DF5TdyMUyswNRGgmK3YA9TX8rWBGm29nt84xQQfK1HB5GeoatjTyHOpUVqzOOmEDek3R9AEp-S2g=), [Source: ardor.cloud](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEebd8yyfTSODps9IdpHaWDdHpZIHd_I72rxvv4uADFtPwa2XP-VfdaTjn6A2hTElrexHfj28DjRJLnUQF-FSGxD-TfuTBh7sy3v9YG-GaLSuxkJ8OyNiE-9OvYOKWfrSq-50KZdqLjRqmZAg8IDiFnUL5z6CB9763snw==), [Source: langfuse.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGk4fIxVvWaS_jtBZliIhGlrCaRyc_cyys3KjjRTXnvhtbs0Tvr6zI26PC-M4kc2bTs78vDo_AUdKWx_GvAqXS21eWyZfsLaxZ1Ou-ZFVBGagIWlu75SIMOjKkyzabwMP64lWphPbcgzri8N_u9AwXsTu8=).\n",
        "*   **Semantic Kernel:** Microsoft's open-source SDK for enterprise-grade GenAI applications, with strong .NET integration [Source: ibm.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHosrTEYdikzOGEDhOr48O82VcrUSK6uJBSUZ_Fw33Mt26nJj5dDU3U4qXYbTCq2U6w3Uazc_JEOikBzUAGbQbsnxR_83ieYfsnV2VwsJyFGXiVsSRAhmYGOfIaYHVgPkermw68u-fIaCrYGynBJBjzIB7lKb4=), [Source: ai21.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF3CKhkZ6nXmTjOaw6mnZnqBWX107UMKghAdGzXtLMfR6Kj8Qr5Xr84Lgnjhw8mNQl1C6S8Pu77NUgLHxaEnIYusM5PXSw1ZJv6mrriI9ujrO_P5LHbuGEhYRvwruP4nuxZZURBHC8639nZa8LTpA==), [Source: ionio.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHP91kYhQCEpDG3jOrSyxauDf9sXWfxG60qBSWCkCQeo75W9ErU_T3eqXtXGn-o5YRZfHDqW-2OET6rYn4Cwe73GWvpGt4FyougReEUVZVlcJeOV7oOMv5DF5TdyMUyswNRGgmK3YA9TX8rWBGm29nt84xQQfK1HB5GeoatjTyHOpUVqzOOmEDek3R9AEp-S2g=), [Source: ardor.cloud](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEebd8yyfTSODps9IdpHaWDdHpZIHd_I72rxvv4uADFtPwa2XP-VfdaTjn6A2hTElrexHfj28DjRJLnUQF-FSGxD-TfuTBh7sy3v9YG-GaLSuxkJ8OyNiE-9OvYOKWfrSq-50KZdqLjRqmZAg8IDiFnUL5z6CB9763snw==).\n",
        "*   **DSPy:** A framework for solving AI tasks using LLMs through declarative and optimizable language model programs [Source: dev.to](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH1O8_mdujAMWlDpiiIEOjILXJoip2RF8HzBZ-_Ds7-qegs20rqZbIqSWqlv4lib_kJKZtDiQiZ4xKaj2TShJtHHdIvuGvvySaX6POhTbeS1IYF6AFdKY-p194OY27bizOGknyeFs-_zFQOClGQ5yVChWCrnIvc2qhusjg1iKDFqg4eiTdApCaFxm7ibTOPk_q5).\n",
        "*   **CrewAI:** Offers a \"Crew\" abstraction for multiple agents with distinct roles, coordinating workflows. It is beginner-friendly, easy to configure, and supports advanced memory and error-handling [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=), [Source: langfuse.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGk4fIxVvWaS_jtBZliIhGlrCaRyc_cyys3KjjRTXnvhtbs0Tvr6zI26PC-M4kc2bTs78vDo_AUdKWx_GvAqXS21eWyZfsLaxZ1Ou-ZFVBGagIWlu75SIMOjKkyzabwMP64lWphPbcgzri8N_u9AwXsTu8=), [Source: turing.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEgNxIKQcN9zpxRpw8t3oGbDc_CXBPSEx1Kzrg-5kHGzj9RjcNX1kqeyLv4MonJlmc2mmmX1tSj2qGWkpmCmUWL-3NJji6YPHYRmkvOsHw36gTumG9cNAqWQwR5cfqsurhdJfG0MdLSzfMqVw9r5w==).\n",
        "*   **OpenAI Agents SDK/Swarm:** The SDK provides tools for building agents that reason, plan, and call APIs. Swarm is a simpler, experimental alternative [Source: ionio.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHP91kYhQCEpDG3jOrSyxauDf9sXWfxG60qBSWCkCQeo75W9ErU_T3eqXtXGn-o5YRZfHDqW-2OET6rYn4Cwe73GWvpGt4FyougReEUVZVlcJeOV7oOMv5DF5TdyMUyswNRGgmK3YA9TX8rWBGm29nt84xQQfK1HB5GeoatjTyHOpUVqzOOmEDek3R9AEp-S2g=), [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=), [Source: langfuse.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGk4fIxVvWaS_jtBZliIhGlrCaRyc_cyys3KjjRTXnvhtbs0Tvr6zI26PC-M4kc2bTs78vDo_AUdKWx_GvAqXS21eWyZfsLaxZ1Ou-ZFVBGagIWlu75SIMOjKkyzabwMP64lWphPbcgzri8N_u9AwXsTu8=).\n",
        "\n",
        "**3.4 Challenges in Multi-Agent Collaboration and Mitigation Strategies**\n",
        "\n",
        "While powerful, multi-agent systems present unique challenges:\n",
        "\n",
        "*   **Scalability:** Coordinating numerous GenAI agents requires robust frameworks to manage complexity and overhead [Source: servixon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0VygXI9kJbfrTxImyfyEhrSRk_Ig84LXoqgS3g9qbhYSspbOv1W6HhJouwlYSE5c2RilO3JODP-nXLesDFVOfiHdgaxBvJjYTUrTrQahVHt9iaGRzmEjFehzwmO-zSaHdiOHJppseoqkbOgGz3jtq1vWuXV95OgoIeu8mU2aszF7qF5G7JzsPMOAcPYlhMcVuqxKmzPgoM-WI4cdsY6Baf8tbZw==), [Source: amazon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXErUcoW5y-wyt1Yy6_dY6WrABdu7lLHvD1pd5n3vdU5mgsTZneZc93hnnfse6ThkGRcG1Du5KU54qu93A0bdhF7eZ1fpIIrJ6Xq-csureQG-M-AFBLhR-8Y-dppNDIpLeCG15n6yRDBnUfgjZr9FdpKcij4GnYs2dbfiBbx3HEWeielVpWFLtGiisgN9ZW4nvnASijjbe9BIidOIC6gkZQ=).\n",
        "*   **Coordination Overhead:** Ensuring agents work harmoniously requires effective task allocation, communication protocols, and conflict resolution to avoid inconsistencies [Source: servixon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0VygXI9kJbfrTxImyfyEhrSRk_Ig84LXoqgS3g9qbhYSspbOv1W6HhJouwlYSE5c2RilO3JODP-nXLesDFVOfiHdgaxBvJjYTUrTrQahVHt9iaGRzmEjFehzwmO-zSaHdiOHJppseoqkbOgGz3jtq1vWuXV95OgoIeu8mU2aszF7qF5G7JzsPMOAcPYlhMcVuqxKmzPgoM-WI4cdsY6Baf8tbZw==), [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHFpaSsqwN_45WXDlZqdu5Iaebl75V-c_oY-BzQQ0QbXKLgPnEEtvW18sh1Q5Qpo7Qiktg4ox4wfbxStITnjWao4vKgHbL28z7waOY2PV-7YSkV8OZm5asQpe1dwvS32NuS1sUAESQcKwV2GytwW3gsVJejeH_Qou5gjRzx41TguJPgJLtTTpyjoZqLsgNeo0eIDP2JXyQ6ce7QS7xfG14QS2fPnL2lEnO1MKJWUDgpJcGoc2t6B21qskybUiM0c68g).\n",
        "*   **Resource Constraints:** The computational intensity of GenAI models can limit real-time multi-agent deployment and present cost challenges [Source: servixon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0VygXI9kJbfrTxImyfyEhrSRk_Ig84LXoqgS3g9qbhYSspbOv1W6HhJouwlYSE5c2RilO3JODP-nXLesDFVOfiHdgaxBvJjYTUrTrQahVHt9iaGRzmEjFehzwmO-zSaHdiOHJppseoqkbOgGz3jtq1vWuXV95OgoIeu8mU2aszF7qF5G7JzsPMOAcPYlhMcVuqxKmzPgoM-WI4cdsY6Baf8tbZw==), [Source: ionio.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHP91kYhQCEpDG3jOrSyxauDf9sXWfxG60qBSWCkCQeo75W9ErU_T3eqXtXGn-o5YRZfHDqW-2OET6rYn4Cwe73GWvpGt4FyougReEUVZVlcJeOV7oOMv5DF5TdyMUyswNRGgmK3YA9TX8rWBGm29nt84xQQfK1HB5GeoatjTyHOpUVqzOOmEDek3R9AEp-S2g=).\n",
        "*   **Security Concerns:** Increased surface area for data leaks as agents access diverse data subsets [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHFpaSsqwN_45WXDlZqdu5Iaebl75V-c_oY-BzQQ0QbXKLgPnEEtvW18sh1Q5Qpo7Qiktg4ox4wfbxStITnjWao4vKgHbL28z7waOY2PV-7YSkV8OZm5asQpe1dwvS32NuS1sUAESQcKwV2GytwW3gsVJejeH_Qou5gjRzx41TguJPgJLtTTpyjoZqLsgNeo0eIDP2JXyQ6ce7QS7xfG14QS2fPnL2lEnO1MKJWUDgpJcGoc2t6B21qskybUiM0c68g), [Source: reply.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHWVYsfwpVf5uXe0TumwleMzHv5JW6z89iNjYMYeC9ZnF__dk9YtS3qsbTtuEB1NHXuejl_kxwAVhCVnGtDun1SHK4ZJeRqONqJZ11j4D1L2QSW-JTC71TbV0k8EkMW9izypdE6wmLbxZ59B6yC7VysNjYMbe8Op-ZWASymzrzlTQrppSD4J2yQg3xyCUr0ZiYUApY98zp9cXEEjty3x5mTm0c0OFbBol0=).\n",
        "*   **Bias Propagation:** Bias can be amplified across agents if not managed carefully [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHFpaSsqwN_45WXDlZqdu5Iaebl75V-c_oY-BzQQ0QbXKLgPnEEtvW18sh1Q5Qpo7Qiktg4ox4wfbxStITnjWao4vKgHbL28z7waOY2PV-7YSkV8OZm5asQpe1dwvS32NuS1sUAESQcKwV2GytwW3gsVJejeH_Qou5gjRzx41TguJPgJLtTTpyjoZqLsgNeo0eIDP2JXyQ6ce7QS7xfG14QS2fPnL2lEnO1MKJWUDgpJcGoc2t6B21qskybUiM0c68g).\n",
        "*   **Complexity of Implementation:** Requires complex control and planning systems, especially for broad objectives [Source: konverso.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEg8hUUDTrCptl0QsZ6lV1yTFHwi-FBhi9IPCI8fLDyb7KGP6HStlJhvgMpL8bM23SWj2-k1QE1kSTKwf5UZhjXxLtfZVhpPJYf0R5wFyRm3cUCqHU7hSY82SQeQ3k2XS4JkaL2W2lt).\n",
        "\n",
        "**Mitigation Strategies:**\n",
        "\n",
        "*   **Robust Frameworks:** Tools like Amazon Bedrock Agents and AutoGen manage collaboration, communication, and task delegation [Source: amazon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXErUcoW5y-wyt1Yy6_dY6WrABdu7lLHvD1pd5n3vdU5mgsTZneZc93hnnfse6ThkGRcG1Du5KU54qu93A0bdhF7eZ1fpIIrJ6Xq-csureQG-M-AFBLhR-8Y-dppNDIpLeCG15n6yRDBnUfgjZr9FdpKcij4GnYs2dbfiBbx3HEWeielVpWFLtGiisgN9ZW4nvnASijjbe9BIidOIC6gkZQ=), [Source: ionio.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHP91kYhQCEpDG3jOrSyxauDf9sXWfxG60qBSWCkCQeo75W9ErU_T3eqXtXGn-o5YRZfHDqW-2OET6rYn4Cwe73GWvpGt4FyougReEUVZVlcJeOV7oOMv5DF5TdyMUyswNRGgmK3YA9TX8rWBGm29nt84xQQfK1HB5GeoatjTyHOpUVqzOOmEDek3R9AEp-S2g=).\n",
        "*   **Defined Communication Protocols:** Clear rules for information exchange and action coordination [Source: servixon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0VygXI9kJbfrTxImyfyEhrSRk_Ig84LXoqgS3g9qbhYSspbOv1W6HhJouwlYSE5c2RilO3JODP-nXLesDFVOfiHdgaxBvJjYTUrTrQahVHt9iaGRzmEjFehzwmO-zSaHdiOHJppseoqkbOgGz3jtq1vWuXV95OgoIeu8mU2aszF7qF5G7JzsPMOAcPYlhMcVuqxKmzPgoM-WI4cdsY6Baf8tbZw==), [Source: indatalabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFR-g8MCahcE0KHlHG39gWmMZPDbr0v3W6agiAlXoLIgTpmiRFj4UHiclf6J6jJvBnmnrHt8CetLHa4t2Vs9QEM4OM6u1rfz3SN7bx55tNFXGxdEh-Bl0yYCxP_9v_fKEUWJ_n8).\n",
        "*   **Specialized Agents:** Breaking tasks into smaller roles for individual agents improves efficiency [Source: amazon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXErUcoW5y-wyt1Yy6_dY6WrABdu7lLHvD1pd5n3vdU5mgsTZneZc93hnnfse6ThkGRcG1Du5KU54qu93A0bdhF7eZ1fpIIrJ6Xq-csureQG-M-AFBLhR-8Y-dppNDIpLeCG15n6yRDBnUfgjZr9FdpKcij4GnYs2dbfiBbx3HEWeielVpWFLtGiisgN9ZW4nvnASijjbe9BIidOIC6gkZQ=), [Source: indatalabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFR-g8MCahcE0KHlHG39gWmMZPDbr0v3W6agiAlXoLIgTpmiRFj4UHiclf6J6jJvBnmnrHt8CetLHa4t2Vs9QEM4OM6u1rfz3SN7bx55tNFXGxdEh-Bl0yYCxP_9v_fKEUWJ_n8).\n",
        "*   **Supervisor Agents:** Can manage workflow by breaking down requests, delegating, and consolidating outputs [Source: amazon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXErUcoW5y-wyt1Yy6_dY6WrABdu7lLHvD1pd5n3vdU5mgsTZneZc93hnnfse6ThkGRcG1Du5KU54qu93A0bdhF7eZ1fpIIrJ6Xq-csureQG-M-AFBLhR-8Y-dppNDIpLeCG15n6yRDBnUfgjZr9FdpKcij4GnYs2dbfiBbx3HEWeielVpWFLtGiisgN9ZW4nvnASijjbe9BIidOIC6gkZQ=).\n",
        "*   **Human-in-the-Loop (HITL):** Ensures responsible deployment and improves reliability [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHFpaSsqwN_45WXDlZqdu5Iaebl75V-c_oY-BzQQ0QbXKLgPnEEtvW18sh1Q5Qpo7Qiktg4ox4wfbxStITnjWao4vKgHbL28z7waOY2PV-7YSkV8OZm5asQpe1dwvS32NuS1sUAESQcKwV2GytwW3gsVJejeH_Qou5gjRzx41TguJPgJLtTTpyjoZqLsgNeo0eIDP2JXyQ6ce7QS7xfG14QS2fPnL2lEnO1MKJWUDgpJcGoc2t6B21qskybUiM0c68g).\n",
        "*   **Data Access Controls:** Strict controls, encryption, audits, and anomaly detection mitigate security risks [Source: reply.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHWVYsfwpVf5uXe0TumwleMzHv5JW6z89iNjYMYeC9ZnF__dk9YtS3qsbTtuEB1NHXuejl_kxwAVhCVnGtDun1SHK4ZJeRqONqJZ11j4D1L2QSW-JTC71TbV0k8EkMW9izypdE6wmLbxZ59B6yC7VysNjYMbe8Op-ZWASymzrzlTQrppSD4J2yQg3xyCUr0ZiYUApY98zp9cXEEjty3x5mTm0c0OFbBol0=).\n",
        "*   **Bias Mitigation Strategies:** Diverse datasets, algorithmic debiasing, and regular audits address bias [Source: xcubelabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEMRZyjJJFxfM5TWt9EgMws-YHjS1kjOSd3bSpTfIZf66fHI4kypZv0qbe-hQQuRWblyLVbwt3yg2XDKgOb82ajZug5PwLUy3Z3G9gTN9bSXxqk5BFUor5XqlubUejFsEa-9bSbTtb60GY3FlXukNKoDNWDHEzCo7RSnuetmswMKAypUGosobIRG2F1JElcXe77aayBguQpb8UM-uTugjqU9Q==), [Source: mdpi.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGIzW3WbzAVKopuvS6LBL5hQRDLs_Mc_oFwtC-eVr_GUlfLKo0Jwsz4ypawuoMROuAY88Vw71Vsi1Y18FPzxFfgX41xZnczMHoN2MDYk7RLAqjVwWx8gzAnnuvL_P8eOqU=), [Source: openreview.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0u2ilK8HeY4G8Qmy7gsF8H6TUk8WeBrVo_MjCzkiDkQe-iADaUmS6s2Sb4rTKpGm57T4FpFEh2yGFQLL7Lw0Vro5yjP7N1akBaxTME2uTNeeFUdHKW73dLRdWzRMdpr_u9vnHUO_LD-pgO8C5CI3yjdshtSlW46U_bpDNU5a3X7Y=), [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXE6tbPsI7cHz4gGFW4Ks0YW6pVvjx1beivjFFFFw3mhpORyW6uQUv2e_y74Qt0ET1G-SLbg_blabpHFJl_GlbcEUjbv847KGLQ_MoSOjURcEXB3mQY2T25ansxXM8rzKuKxhIrf7ayPicbtlzQxG9vDENVKWrktmK_urJ1_17IYoCG7zq6W2-AfVQqps2OT4EDrw1gQOG25zQzBwDJEVEm1Kyz0foY0COhghpSsls2kq86h9rOITUco8PdPjxXG2Q0dNitjehzZ10Bn7dc=).\n",
        "\n",
        "**3.5 Best Practices for Evaluating GenAI Agents**\n",
        "\n",
        "Effective evaluation is crucial for reliable AI systems:\n",
        "\n",
        "*   **Key Metrics:** Include latency, cost, token usage, accuracy, perplexity, log-likelihood, BLEU, and ROUGE scores [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=), [Source: antiersolutions.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHzbAxojem4i7qa3qSSMGzOxoUly5hlfwO9kgObI7yEVmMM2ToR1EEcVguTTaFYpD2g53SGCkLHzCIKT1jRgr3F29FQRBQXD5isnnjXWq8r0NC3v6ypX3KA1_AZIALgtUv66udR8pNFTlcW2LUuR1GsRs9RpLrU3r1jxIhJwVq-QizAxgKcUEP8a0BFtXwJ5B2VlURFsNthtDbF).\n",
        "*   **Evaluation Strategies:**\n",
        "    *   **Automated Benchmarks and Testing:** Fast, scalable, and consistent for comparisons [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=). Benchmarks offer curated datasets and leaderboards [Source: antiersolutions.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHzbAxojem4i7qa3qSSMGzOxoUly5hlfwO9kgObI7yEVmMM2ToR1EEcVguTTaFYpD2g53SGCkLHzCIKT1jRgr3F29FQRBQXD5isnnjXWq8r0NC3v6ypX3KA1_AZIALgtUv66udR8pNFTlcW2LUuR1GsRs9RpLrU3r1jxIhJwVq-QizAxgKcUEP8a0BFtXwJ5B2VlURFsNthtDbF).\n",
        "    *   **Human-in-the-Loop (HITL) Testing:** Essential for nuanced aspects and user feedback, especially when no single \"true\" response exists [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=), [Source: datastax.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHrNCZ61HkNvxogscsl1wwPxYJ9WHL64Z8PHkNfPnPqdljRuCS7AAcd8FzBUeUbmhdYoPSL-dpT1nyGaIlm11I88hVgWKf8rdHwYGHFs8NPt-jnolARKjQmrBk-WSdcvw9uV9MsIapp4dWbU8WIsfI4fp6CuWuPcngFPeg0d80=), [Source: antiersolutions.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHzbAxojem4i7qa3qSSMGzOxoUly5hlfwO9kgObI7yEVmMM2ToR1EEcVguTTaFYpD2g53SGCkLHzCIKT1jRgr3F29FQRBQXD5isnnjXWq8r0NC3v6ypX3KA1_AZIALgtUv66udR8pNFTlcW2LUuR1GsRs9RpLrU3r1jxIhJwVq-QizAxgKcUEP8a0BFtXwJ5B2VlURFsNthtDbF).\n",
        "    *   **Reproducibility:** Ensures results are trustworthy and comparable [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=).\n",
        "*   **Best Practices:** Combine quantitative and qualitative methods; tailor metrics to the use case; conduct robustness tests; implement continuous monitoring; document and version everything; iterate and refine; assess for bias and fairness; check for groundedness, relevance, coherence, and fluency [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=), [Source: datastax.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHrNCZ61HkNvxogscsl1wwPxYJ9WHL64Z8PHkNfPnPqdljRuCS7AAcd8FzBUeUbmhdYoPSL-dpT1nyGaIlm11I88hVgWKf8rdHwYGHFs8NPt-jnolARKjQmrBk-WSdcvw9uV9MsIapp4dWbU8WIsfI4fp6CuWuPcngFPeg0d80=), [Source: antiersolutions.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHzbAxojem4i7qa3qSSMGzOxoUly5hlfwO9kgObI7yEVmMM2ToR1EEcVguTTaFYpD2g53SGCkLHzCIKT1jRgr3F29FQRBQXD5isnnjXWq8r0NC3v6ypX3KA1_AZIALgtUv66udR8pNFTlcW2LUuR1GsRs9RpLrU3r1jxIhJwVq-QizAxgKcUEP8a0BFtXwJ5B2VlURFsNthtDbF), [Source: code4thought.eu](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHDcIzF6RTa82wbwl3L2b2V64nunYqKmVgkWO2rK2uKv9Bw_uoCNeqCJRAIAMaHJ7Sqdowkp9Qg0r1kX9odR1KJa9oKQYQbn1rkxfCxG_X33gdO3x9sBCxkoOMoFFagjsVSwfeC_bVwpDhAUtfgLyhkJ_1Z7-dIJlt4TAumrm35VDDgcUfWrYRyIq_YP0Nk7dezil8TA6AEDTE91Qt-YvIYgbKEXcH6).\n",
        "\n",
        "**3.6 Ethical Considerations and Bias Mitigation**\n",
        "\n",
        "Ethical implications are significant in GenAI agent development:\n",
        "\n",
        "*   **Bias:** Models can perpetuate biases from skewed training data, leading to discriminatory outcomes [Source: xcubelabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEMRZyjJJFxfM5TWt9EgMws-YHjS1kjOSd3bSpTfIZf66fHI4kypZv0qbe-hQQuRWblyLVbwt3yg2XDKgOb82ajZug5PwLUy3Z3G9gTN9bSXxqk5BFUor5XqlubUejFsEa-9bSbTtb60GY3FlXukNKoDNWDHEzCo7RSnuetmswMKAypUGosobIRG2F1JElcXe77aayBguQpb8UM-uTugjqU9Q==), [Source: mdpi.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGIzW3WbzAVKopuvS6LBL5hQRDLs_Mc_oFwtC-eVr_GUlfLKo0Jwsz4ypawuoMROuAY88Vw71Vsi1Y18FPzxFfgX41xZnczMHoN2MDYk7RLAqjVwWx8gzAnnuvL_P8eOqU=), [Source: openreview.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0u2ilK8HeY4G8Qmy7gsF8H6TUk8WeBrVo_MjCzkiDkQe-iADaUmS6s2Sb4rTKpGm57T4FpFEh2yGFQLL7Lw0Vro5yjP7N1akBaxTME2uTNeeFUdHKW73dLRdWzRMdpr_u9vnHUO_LD-pgO8C5CI3yjdshtSlW46U_bpDNU5a3X7Y=), [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXE6tbPsI7cHz4gGFW4Ks0YW6pVvjx1beivjFFFFw3mhpORyW6uQUv2e_y74Qt0ET1G-SLbg_blabpHFJl_GlbcEUjbv847KGLQ_MoSOjURcEXB3mQY2T25ansxXM8rzKuKxhIrf7ayPicbtlzQxG9vDENVKWrktmK_urJ1_17IYoCG7zq6W2-AfVQqps2OT4EDrw1gQOG25zQzBwDJEVEm1Kyz0foY0COhghpSsls2kq86h9rOITUco8PdPjxXG2Q0dNitjehzZ10Bn7dc=). Bias can stem from data, algorithms, and human oversight [Source: openreview.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0u2ilK8HeY4G8Qmy7gsF8H6TUk8WeBrVo_MjCzkiDkQe-iADaUmS6s2Sb4rTKpGm57T4FpFEh2yGFQLL7Lw0Vro5yjP7N1akBaxTME2uTNeeFUdHKW73dLRdWzRMdpr_u9vnHUO_LD-pgO8C5CI3yjdshtSlW46U_bpDNU5a3X7Y=).\n",
        "*   **Misinformation and Deepfakes:** GenAI's ability to create convincing synthetic media poses threats [Source: mdpi.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGIzW3WbzAVKopuvS6LBL5hQRDLs_Mc_oFwtC-eVr_GUlfLKo0Jwsz4ypawuoMROuAY88Vw71Vsi1Y18FPzxFfgX41xZnczMHoN2MDYk7RLAqjVwWx8gzAnnuvL_P8eOqU=), [Source: openreview.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0u2ilK8HeY4G8Qmy7gsF8H6TUk8WeBrVo_MjCzkiDkQe-iADaUmS6s2Sb4rTKpGm57T4FpFEh2yGFQLL7Lw0Vro5yjP7N1akBaxTME2uTNeeFUdHKW73dLRdWzRMdpr_u9vnHUO_LD-pgO8C5CI3yjdshtSlW46U_bpDNU5a3X7Y=).\n",
        "*   **Privacy Infringement:** Data collection practices can overstep ethical boundaries [Source: mdpi.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGIzW3WbzAVKopuvS6LBL5hQRDLs_Mc_oFwtC-eVr_GUlfLKo0Jwsz4ypawuoMROuAY88Vw71Vsi1Y18FPzxFfgX41xZnczMHoN2MDYk7RLAqjVwWx8gzAnnuvL_P8eOqU=), [Source: openreview.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0u2ilK8HeY4G8Qmy7gsF8H6TUk8WeBrVo_MjCzkiDkQe-iADaUmS6s2Sb4rTKpGm57T4FpFEh2yGFQLL7Lw0Vro5yjP7N1akBaxTME2uTNeeFUdHKW73dLRdWzRMdpr_u9vnHUO_LD-pgO8C5CI3yjdshtSlW46U_bpDNU5a3X7Y=).\n",
        "*   **Accountability and Transparency:** Opaque model training and lack of clear regulations are concerns [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXE6tbPsI7cHz4gGFW4Ks0YW6pVvjx1beivjFFFFw3mhpORyW6uQUv2e_y74Qt0ET1G-SLbg_blabpHFJl_GlbcEUjbv847KGLQ_MoSOjURcEXB3mQY2T25ansxXM8rzKuKxhIrf7ayPicbtlzQxG9vDENVKWrktmK_urJ1_17IYoCG7zq6W2-AfVQqps2OT4EDrw1gQOG25zQzBwDJEVEm1Kyz0foY0COhghpSsls2kq86h9rOITUco8PdPjxXG2Q0dNitjehzZ10Bn7dc=). Tracing decision-making in multi-agent systems can be challenging [Source: reply.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHWVYsfwpVf5uXe0TumwleMzHv5JW6z89iNjYMYeC9ZnF__dk9YtS3qsbTtuEB1NHXuejl_kxwAVhCVnGtDun1SHK4ZJeRqONqJZ11j4D1L2QSW-JTC71TbV0k8EkMW9izypdE6wmLbxZ59B6yC7VysNjYMbe8Op-ZWASymzrzlTQrppSD4J2yQg3xyCUr0ZiYUApY98zp9cXEEjty3x5mTm0c0OFbBol0=).\n",
        "*   **Misuse of Tools:** Agents with tool access could be dangerous if misused [Source: microsoft.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGfXtf-tcnkotGbVR9QgJSzSSAQmRH-Gv0BIDQmtjew37j52yIrYv2a4G7jcjUUoerYO7lVNSwETXsR0H_SQ1--MSscmIoGHRLdfWCG--ieFSr9RH8B8wO0OEHa-f3xLKJMtdDH49zcle21YH2uR_i61dnUajn9oXDri4zskS4rFLnVyY89OYhOyP3Gpdd2YCOfyFiBS1mzgzddmompq-2AqPKR).\n",
        "*   **Anthropomorphism:** Users may over-rely on agents or mistakenly believe they are fully aligned with their interests [Source: microsoft.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGfXtf-tcnkotGbVR9QgJSzSSAQmRH-Gv0BIDQmtjew37j52yIrYv2a4G7jcjUUoerYO7lVNSwETXsR0H_SQ1--MSscmIoGHRLdfWCG--ieFSr9RH8B8wO0OEHa-f3xLKJMtdDH49zcle21YH2uR_i61dnUajn9oXDri4zskS4rFLnVyY89OYhOyP3Gpdd2YCOfyFiBS1mzgzddmompq-2AqPKR).\n",
        "\n",
        "**Mitigation Strategies:**\n",
        "\n",
        "*   **Diverse and Representative Datasets:** Curate high-quality, diverse data and analyze for imbalances; use data augmentation and anonymization [Source: xcubelabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEMRZyjJJFxfM5TWt9EgMws-YHjS1kjOSd3bSpTfIZf66fHI4kypZv0qbe-hQQuRWblyLVbwt3yg2XDKgOb82ajZug5PwLUy3Z3G9gTN9bSXxqk5BFUor5XqlubUejFsEa-9bSbTtb60GY3FlXukNKoDNWDHEzCo7RSnuetmswMKAypUGosobIRG2F1JElcXe77aayBguQpb8UM-uTugjqU9Q==), [Source: mdpi.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGIzW3WbzAVKopuvS6LBL5hQRDLs_Mc_oFwtC-eVr_GUlfLKo0Jwsz4ypawuoMROuAY88Vw71Vsi1Y18FPzxFfgX41xZnczMHoN2MDYk7RLAqjVwWx8gzAnnuvL_P8eOqU=), [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXE6tbPsI7cHz4gGFW4Ks0YW6pVvjx1beivjFFFFw3mhpORyW6uQUv2e_y74Qt0ET1G-SLbg_blabpHFJl_GlbcEUjbv847KGLQ_MoSOjURcEXB3mQY2T25ansxXM8rzKuKxhIrf7ayPicbtlzQxG9vDENVKWrktmK_urJ1_17IYoCG7zq6W2-AfVQqps2OT4EDrw1gQOG25zQzBwDJEVEm1Kyz0foY0COhghpSsls2kq86h9rOITUco8PdPjxXG2Q0dNitjehzZ10Bn7dc=), [Source: mckinsey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEL75UFZdIfM3in-DyGcpG2liOeg1ZuFEOS4DjRO2C3DgTJb2j4BQr9R-j0xB3jakpVSsS0Kpf2TcLwP0a2Nn-7FAx8uXkfALcvgOb-HjvYSp4L0eC3juDBPtP2IWkXhUmsxuyFlU2EI8RvisEhTohZ_XnkIS3OvBJq_08IbaUYsej4XidUdHnM0DrnjrMaYX-8-fFghO_j_-toXFSGRWjhZprOa0P-GzbSpMsQ7Di2).\n",
        "*   **Algorithmic Debiasing:** Use techniques like re-weighting, adversarial debiasing, or RLHF [Source: datastax.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHrNCZ61HkNvxogscsl1wwPxYJ9WHL64Z8PHkNfPnPqdljRuCS7AAcd8FzBUeUbmhdYoPSL-dpT1nyGaIlm11I88hVgWKf8rdHwYGHFs8NPt-jnolARKjQmrBk-WSdcvw9uV9MsIapp4dWbU8WIsfI4fp6CuWuPcngFPeg0d80=), [Source: xcubelabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEMRZyjJJFxfM5TWt9EgMws-YHjS1kjOSd3bSpTfIZf66fHI4kypZv0qbe-hQQuRWblyLVbwt3yg2XDKgOb82ajZug5PwLUy3Z3G9gTN9bSXxqk5BFUor5XqlubUejFsEa-9bSbTtb60GY3FlXukNKoDNWDHEzCo7RSnuetmswMKAypUGosobIRG2F1JElcXe77aayBguQpb8UM-uTugjqU9Q==).\n",
        "*   **Transparency and Explainability (XAI):** Document model development, data, and decision processes [Source: xcubelabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEMRZyjJJFxfM5TWt9EgMws-YHjS1kjOSd3bSpTfIZf66fHI4kypZv0qbe-hQQuRWblyLVbwt3yg2XDKgOb82ajZug5PwLUy3Z3G9gTN9bSXxqk5BFUor5XqlubUejFsEa-9bSbTtb60GY3FlXukNKoDNWDHEzCo7RSnuetmswMKAypUGosobIRG2F1JElcXe77aayBguQpb8UM-uTugjqU9Q==), [Source: openreview.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0u2ilK8HeY4G8Qmy7gsF8H6TUk8WeBrVo_MjCzkiDkQe-iADaUmS6s2Sb4rTKpGm57T4FpFEh2yGFQLL7Lw0Vro5yjP7N1akBaxTME2uTNeeFUdHKW73dLRdWzRMdpr_u9vnHUO_LD-pgO8C5CI3yjdshtSlW46U_bpDNU5a3X7Y=), [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXE6tbPsI7cHz4gGFW4Ks0YW6pVvjx1beivjFFFFw3mhpORyW6uQUv2e_y74Qt0ET1G-SLbg_blabpHFJl_GlbcEUjbv847KGLQ_MoSOjURcEXB3mQY2T25ansxXM8rzKuKxhIrf7ayPicbtlzQxG9vDENVKWrktmK_urJ1_17IYoCG7zq6W2-AfVQqps2OT4EDrw1gQOG25zQzBwDJEVEm1Kyz0foY0COhghpSsls2kq86h9rOITUco8PdPjxXG2Q0dNitjehzZ10Bn7dc=). Logging systems and XAI can aid accountability [Source: reply.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHWVYsfwpVf5uXe0TumwleMzHv5JW6z89iNjYMYeC9ZnF__dk9YtS3qsbTtuEB1NHXuejl_kxwAVhCVnGtDun1SHK4ZJeRqONqJZ11j4D1L2QSW-JTC71TbV0k8EkMW9izypdE6wmLbxZ59B6yC7VysNjYMbe8Op-ZWASymzrzlTQrppSD4J2yQg3xyCUr0ZiYUApY98zp9cXEEjty3x5mTm0c0OFbBol0=).\n",
        "*   **Human Oversight and Governance:** Integrate HITL and establish robust governance frameworks [Source: researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHFpaSsqwN_45WXDlZqdu5Iaebl75V-c_oY-BzQQ0QbXKLgPnEEtvW18sh1Q5Qpo7Qiktg4ox4wfbxStITnjWao4vKgHbL28z7waOY2PV-7YSkV8OZm5asQpe1dwvS32NuS1sUAESQcKwV2GytwW3gsVJejeH_Qou5gjRzx41TguJPgJLtTTpyjoZqLsgNeo0eIDP2JXyQ6ce7QS7xfG14QS2fPnL2lEnO1MKJWUDgpJcGoc2t6B21qskybUiM0c68g), [Source: datastax.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHrNCZ61HkNvxogscsl1wwPxYJ9WHL64Z8PHkNfPnPqdljRuCS7AAcd8FzBUeUbmhdYoPSL-dpT1nyGaIlm11I88hVgWKf8rdHwYGHFs8NPt-jnolARKjQmrBk-WSdcvw9uV9MsIapp4dWbU8WIsfI4fp6CuWuPcngFPeg0d80=), [Source: xcubelabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEMRZyjJJFxfM5TWt9EgMws-YHjS1kjOSd3bSpTfIZf66fHI4kypZv0qbe-hQQuRWblyLVbwt3yg2XDKgOb82ajZug5PwLUy3Z3G9gTN9bSXxqk5BFUor5XqlubUejFsEa-9bSbTtb60GY3FlXukNKoDNWDHEzCo7RSnuetmswMKAypUGosobIRG2F1JElcXe77aayBguQpb8UM-uTugjqU9Q==), [Source: mckinsey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEL75UFZdIfM3in-DyGcpG2liOeg1ZuFEOS4DjRO2C3DgTJb2j4BQr9R-j0xB3jakpVSsS0Kpf2TcLwP0a2Nn-7FAx8uXkfALcvgOb-HjvYSp4L0eC3juDBPtP2IWkXhUmsxuyFlU2EI8RvisEhTohZ_XnkIS3OvBJq_08IbaUYsej4XidUdHnM0DrnjrMaYX-8-fFghO_j_-toXFSGRWjhZprOa0P-GzbSpMsQ7Di2).\n",
        "*   **Guardrails and Safety Modules:** Implement safety layers to filter or block risky outputs [Source: skyflow.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFBJAg1vrfWJfd8YK7W4KBKxA_r824pyXuE_FffSByc-1087jTUgFPJYK8fId5DCzyOXwmCCgZ6Si0YTudarsDn0KJIv1Z8zN4V2Sb9aj2-BXsmF4VZhzpbimBq_t-OLn4mCrW9PkpbDOFxfe8A7NM=).\n",
        "*   **Ethical AI Development:** Prioritize ethics from the design phase [Source: servixon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0VygXI9kJbfrTxImyfyEhrSRk_Ig84LXoqgS3g9qbhYSspbOv1W6HhJouwlYSE5c2RilO3JODP-nXLesDFVOfiHdgaxBvJjYTUrTrQahVHt9iaGRzmEjFehzwmO-zSaHdiOHJppseoqkbOgGz3jtq1vWuXV95OgoIeu8mU2aszF7qF5G7JzsPMOAcPYlhMcVuqxKmzPgoM-WI4cdsY6Baf8tbZw==), [Source: mdpi.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGIzW3WbzAVKopuvS6LBL5hQRDLs_Mc_oFwtC-eVr_GUlfLKo0Jwsz4ypawuoMROuAY88Vw71Vsi1Y18FPzxFfgX41xZnczMHoN2MDYk7RLAqjVwWx8gzAnnuvL_P8eOqU=).\n",
        "\n",
        "**3.7 Impact of LLM Choice on GenAI Agent Architecture**\n",
        "\n",
        "The choice of LLM is fundamental to an agent's architecture and capabilities:\n",
        "\n",
        "*   **Core Functionality:** The LLM provides natural language understanding, reasoning, and generalizability [Source: skyflow.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFBJAg1vrfWJfd8YK7W4KBKxA_r824pyXuE_FffSByc-1087jTUgFPJYK8fId5DCzyOXwmCCgZ6Si0YTudarsDn0KJIv1Z8zN4V2Sb9aj2-BXsmF4VZhzpbimBq_t-OLn4mCrW9PkpbDOFxfe8A7NM=). It serves as the agent's cognitive center [Source: beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFyiyo719tpZNJi2j6Pydj0eVQxD0lXsB_g0HNYX0e1iw6rpwQFUMb2VJSU-FiarUX5DCMBNvh3EjVFjjSt-BUDcxq0V5xUGC5uCmgvajJEizVyIy0BqffDxmt07NB65rNwZ_F5qYjrM5FW4Kk-NI2_W4D-uAnuOlqCTEQ79zVY2Q==).\n",
        "*   **Specialization:** Different LLMs excel at different tasks (e.g., Codex for coding, GPT-4 for general proficiency); the \"brain needs to fit the task\" [Source: beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFyiyo719tpZNJi2j6Pydj0eVQxD0lXsB_g0HNYX0e1iw6rpwQFUMb2VJSU-FiarUX5DCMBNvh3EjVFjjSt-BUDcxq0V5xUGC5uCmgvajJEizVyIy0BqffDxmt07NB65rNwZ_F5qYjrM5FW4Kk-NI2_W4D-uAnuOlqCTEQ79zVY2Q==).\n",
        "*   **Performance:** Agentic workflows leveraging reflection, tool use, and multi-agent collaboration around LLMs can yield exponential performance gains [Source: konverso.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEg8hUUDTrCptl0QsZ6lV1yTFHwi-FBhi9IPCI8fLDyb7KGP6HStlJhvgMpL8bM23SWj2-k1QE1kSTKwf5UZhjXxLtfZVhpPJYf0R5wFyRm3cUCqHU7hSY82SQeQ3k2XS4JkaL2W2lt).\n",
        "*   **Limitations and Architecture Adaptation:** Single-agent LLM systems may struggle with long context, specialized knowledge, privacy, and security. Multi-agent architectures can distribute tasks to address these [Source: reply.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHWVYsfwpVf5uXe0TumwleMzHv5JW6z89iNjYMYeC9ZnF__dk9YtS3qsbTtuEB1NHXuejl_kxwAVhCVnGtDun1SHK4ZJeRqONqJZ11j4D1L2QSW-JTC71TbV0k8EkMW9izypdE6wmLbxZ59B6yC7VysNjYMbe8Op-ZWASymzrzlTQrppSD4J2yQg3xyCUr0ZiYUApY98zp9cXEEjty3x5mTm0c0OFbBol0=). The architecture must leverage LLM strengths and mitigate weaknesses (e.g., using memory-augmented context windows for LLMs with limited context length [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=)).\n",
        "*   **Cost and Computational Intensity:** More powerful LLMs can be computationally intensive, impacting resource constraints and costs [Source: servixon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0VygXI9kJbfrTxImyfyEhrSRk_Ig84LXoqgS3g9qbhYSspbOv1W6HhJouwlYSE5c2RilO3JODP-nXLesDFVOfiHdgaxBvJjYTUrTrQahVHt9iaGRzmEjFehzwmO-zSaHdiOHJppseoqkbOgGz3jtq1vWuXV95OgoIeu8mU2aszF7qF5G7JzsPMOAcPYlhMcVuqxKmzPgoM-WI4cdsY6Baf8tbZw==), [Source: wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=).\n",
        "\n",
        "### **4. Conclusion**\n",
        "\n",
        "Architecting GenAI agents is a complex endeavor that requires careful consideration of modular components, appropriate design patterns, and suitable development frameworks. The choice of LLM forms the cognitive core of the agent and profoundly influences its capabilities and the surrounding architecture. As agents become more sophisticated, particularly in multi-agent collaborations, addressing challenges related to scalability, coordination, security, and ethical considerations becomes increasingly critical. Robust evaluation practices, combining automated metrics with human oversight, are essential for ensuring reliability and trustworthiness. Ultimately, a thoughtful, iterative, and ethically-grounded approach to GenAI agent architecture is paramount for harnessing their transformative potential responsibly.\n",
        "\n",
        "### **5. Sources**\n",
        "\n",
        "*   **[amazon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXG4ZgjexrCnT0w6Ap1kFkD4VX7TQm-NqHYNyt0AxvEz1w02_DmjeXdPmOAlXFycH056zqy1mLd9DY-FSkVu4QqtiG-YhesCMWcWa2EmSg4p50_ENeYznXw2pRqIOB2M3hmVXhZbicwSdObi1dmYPHjHZC8FJ4SdV0IB8VipQJ5ycptQyS-KqIkWfSX8dKTc5eat1wo66tr6KklL8seVUnQO7CHe9OdxytPp_9L_ZwxNDrQIyQICMHNLPLVqe3oJ_7JIA7QPMQsmYIKV)**\n",
        "*   **[amazon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXErUcoW5y-wyt1Yy6_dY6WrABdu7lLHvD1pd5n3vdU5mgsTZneZc93hnnfse6ThkGRcG1Du5KU54qu93A0bdhF7eZ1fpIIrJ6Xq-csureQG-M-AFBLhR-8Y-dppNDIpLeCG15n6yRDBnUfgjZr9FdpKcij4GnYs2dbfiBbx3HEWeielVpWFLtGiisgN9ZW4nvnASijjbe9BIidOIC6gkZQ=)**\n",
        "*   **[analyticsvidhya.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFXODLyZ4Q0D7PjpnYoSpXCj704ZddZOOADYbORwVSFiVGN5o20sfSk-3Ljuz1uSnoHGoeaqwgU-kfS2kH1w76NSOMLjR0ZkBPjWhi47_9iLVc4NR_ZH8-KIv8y3sZznkzE1uJJmsLc0CHRh-LrDTMS8DjxOngL9Od2-aU_aUjb1A==)**\n",
        "*   **[antiersolutions.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHzbAxojem4i7qa3qSSMGzOxoUly5hlfwO9kgObI7yEVmMM2ToR1EEcVguTTaFYpD2g53SGCkLHzCIKT1jRgr3F29FQRBQXD5isnnjXWq8r0NC3v6ypX3KA1_AZIALgtUv66udR8pNFTlcW2LUuR1GsRs9RpLrU3r1jxIhJwVq-QizAxgKcUEP8a0BFtXwJ5B2VlURFsNthtDbF)**\n",
        "*   **[ardor.cloud](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEebd8yyfTSODps9IdpHaWDdHpZIHd_I72rxvv4uADFtPwa2XP-VfdaTjn6A2hTElrexHfj28DjRJLnUQF-FSGxD-TfuTBh7sy3v9YG-GaLSuxkJ8OyNiE-9OvYOKWfrSq-50KZdqLjRqmZAg8IDiFnUL5z6CB9763snw==)**\n",
        "*   **[ai21.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF3CKhkZ6nXmTjOaw6mnZnqBWX107UMKghAdGzXtLMfR6Kj8Qr5Xr84Lgnjhw8mNQl1C6S8Pu77NUgLHxaEnIYusM5PXSw1ZJv6mrriI9ujrO_P5LHbuGEhYRvwruP4nuxZZURBHC8639nZa8LTpA==)**\n",
        "*   **[beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEQ6puVsP7gH6FnAeh9mKDlRb6BKpyod2DKpjI8kFsNAwI6f2KKmBs-znCkMLuEMwQIhca-6geEoPZlNrwj1Oe6KLOi2liqQbMDVRGuc_fwbrIOEnFouuCy-WdO64mjtIEV_bRnEdbJ2ng5WOu1BuyVBI6pjRvmBjKwhxqsEbEJaJA=)**\n",
        "*   **[beyondkey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFyiyo719tpZNJi2j6Pydj0eVQxD0lXsB_g0HNYX0e1iw6rpwQFUMb2VJSU-FiarUX5DCMBNvh3EjVFjjSt-BUDcxq0V5xUGC5uCmgvajJEizVyIy0BqffDxmt07NB65rNwZ_F5qYjrM5FW4Kk-NI2_W4D-uAnuOlqCTEQ79zVY2Q==)**\n",
        "*   **[brightdata.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHdSe3DR5Wy90p1uZBX-zly8tJY5e1WNvGyCJKbI2lFoH2waKzo9D5CLfqZ9mnu_I_pTD1MTNR8qJWBa7jrr-8D9ytYSKhUSvPvrTmK0EKOiO9Ih87SJunfDZiIlex2cEQ9JhW6AGL_uVJC2t4yDmHGkX4=)**\n",
        "*   **[code4thought.eu](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHDcIzF6RTa82wbwl3L2b2V64nunYqKmVgkWO2rK2uKv9Bw_uoCNeqCJRAIAMaHJ7Sqdowkp9Qg0r1kX9odR1KJa9oKQYQbn1rkxfCxG_X33gdO3x9sBCxkoOMoFFagjsVSwfeC_bVwpDhAUtfgLyhkJ_1Z7-dIJlt4TAumrm35VDDgcUfWrYRyIq_YP0Nk7dezil8TA6AEDTE91Qt-YvIYgbKEXcH6)**\n",
        "*   **[datastax.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHrNCZ61HkNvxogscsl1wwPxYJ9WHL64Z8PHkNfPnPqdljRuCS7AAcd8FzBUeUbmhdYoPSL-dpT1nyGaIlm11I88hVgWKf8rdHwYGHFs8NPt-jnolARKjQmrBk-WSdcvw9uV9MsIapp4dWbU8WIsfI4fp6CuWuPcngFPeg0d80=)**\n",
        "*   **[dev.to](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH1O8_mdujAMWlDpiiIEOjILXJoip2RF8HzBZ-_Ds7-qegs20rqZbIqSWqlv4lib_kJKZtDiQiZ4xKaj2TShJtHHdIvuGvvySaX6POhTbeS1IYF6AFdKY-p194OY27bizOGknyeFs-_zFQOClGQ5yVChWCrnIvc2qhusjg1iKDFqg4eiTdApCaFxm7ibTOPk_q5)**\n",
        "*   **[dsstream.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXG78-3aCiGyn5dk7kBVfnmX0MfU1GXkdUYeQaucJq-LrAvI9ihGENQIpM1dE6Ogbp6X-3csZjMhzuqcElPYw5C3htq98Y6pQMoM5ByB8cFJpO-DnXctovGcBzz4V_7LmQ_dR2yyyOawqxAo9kNy-MbOfSOMDNv9UiqP0zSssivLoNToJCKWj1fuP42Myeh_MDEwZxuguufTJBYFzBkX)**\n",
        "*   **[ibm.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHosrTEYdikzOGEDhOr48O82VcrUSK6uJBSUZ_Fw33Mt26nJj5dDU3U4qXYbTCq2U6w3Uazc_JEOikBzUAGbQbsnxR_83ieYfsnV2VwsJyFGXiVsSRAhmYGOfIaYHVgPkermw68u-fIaCrYGynBJBjzIB7lKb4=)**\n",
        "*   **[indatalabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFR-g8MCahcE0KHlHG39gWmMZPDbr0v3W6agiAlXoLIgTpmiRFj4UHiclf6J6jJvBnmnrHt8CetLHa4t2Vs9QEM4OM6u1rfz3SN7bx55tNFXGxdEh-Bl0yYCxP_9v_fKEUWJ_n8)**\n",
        "*   **[ionio.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHP91kYhQCEpDG3jOrSyxauDf9sXWfxG60qBSWCkCQeo75W9ErU_T3eqXtXGn-o5YRZfHDqW-2OET6rYn4Cwe73GWvpGt4FyougReEUVZVlcJeOV7oOMv5DF5TdyMUyswNRGgmK3YA9TX8rWBGm29nt84xQQfK1HB5GeoatjTyHOpUVqzOOmEDek3R9AEp-S2g=)**\n",
        "*   **[konverso.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEg8hUUDTrCptl0QsZ6lV1yTFHwi-FBhi9IPCI8fLDyb7KGP6HStlJhvgMpL8bM23SWj2-k1QE1kSTKwf5UZhjXxLtfZVhpPJYf0R5wFyRm3cUCqHU7hSY82SQeQ3k2XS4JkaL2W2lt)**\n",
        "*   **[langfuse.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGk4fIxVvWaS_jtBZliIhGlrCaRyc_cyys3KjjRTXnvhtbs0Tvr6zI26PC-M4kc2bTs78vDo_AUdKWx_GvAqXS21eWyZfsLaxZ1Ou-ZFVBGagIWlu75SIMOjKkyzabwMP64lWphPbcgzri8N_u9AwXsTu8=)**\n",
        "*   **[leewayhertz.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEs3TEfEeGPyeDj_1ftEQgmAbhODIcO8XAyiTAi6lK5SwhYfJEV8YcCtkwwfE23XTpWnrU9CsUBYpUZOcW0-xrGt3ei1UuN7QwVX79u3zOh9Rl8d-gHleZmtkG189sDbnirzSK6TU33wIxpw4BYhtCQ)**\n",
        "*   **[mckinsey.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEL75UFZdIfM3in-DyGcpG2liOeg1ZuFEOS4DjRO2C3DgTJb2j4BQr9R-j0xB3jakpVSsS0Kpf2TcLwP0a2Nn-7FAx8uXkfALcvgOb-HjvYSp4L0eC3juDBPtP2IWkXhUmsxuyFlU2EI8RvisEhTohZ_XnkIS3OvBJq_08IbaUYsej4XidUdHnM0DrnjrMaYX-8-fFghO_j_-toXFSGRWjhZprOa0P-GzbSpMsQ7Di2)**\n",
        "*   **[mdpi.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGIzW3WbzAVKopuvS6LBL5hQRDLs_Mc_oFwtC-eVr_GUlfLKo0Jwsz4ypawuoMROuAY88Vw71Vsi1Y18FPzxFfgX41xZnczMHoN2MDYk7RLAqjVwWx8gzAnnuvL_P8eOqU=)**\n",
        "*   **[microsoft.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEK8QygjQJ_MFFNUoW2TfEBx2q_BA_RMA-pCoqIggvwUrjKrO8dv85UD9wy-C_jZ3DYEGtLv6x-Y5-3wvRLjutXPJoRLLz6ctmbNsJl-yz8Tm8hAxDMr0cymEdTNC13r6vRTOgofObUD9l0vujU9Hby_kMJ3M9XBDJCrX-dnfa7uopr9Tkc6Ee-cupQHyZ7aik6rEEswTHyYLi7e98J_aiZTiHbECIxSnkq7OLJqKLWBy59TQ==)**\n",
        "*   **[microsoft.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGfXtf-tcnkotGbVR9QgJSzSSAQmRH-Gv0BIDQmtjew37j52yIrYv2a4G7jcjUUoerYO7lVNSwETXsR0H_SQ1--MSscmIoGHRLdfWCG--ieFSr9RH8B8wO0OEHa-f3xLKJMtdDH49zcle21YH2uR_i61dnUajn9oXDri4zskS4rFLnVyY89OYhOyP3Gpdd2YCOfyFiBS1mzgzddmompq-2AqPKR)**\n",
        "*   **[mongodb.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF7ed62gl7MOVhqwRGUhClOBjk0_z5Vt1H2fLjc8_5Ry46eY-Z2l8sbh6NW9CrqDA3Gku1Xb141ZgOeCvPumbz9z77UuGKFpT-8sKYeGJCs158zwhpTwpS5tA1bFIoKI_Qkbuj3i_sNzmzRRLx4kKCs6gVfYPclquxqBsD2gWKHc_Brv24SBM8uCCyq)**\n",
        "*   **[openreview.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0u2ilK8HeY4G8Qmy7gsF8H6TUk8WeBrVo_MjCzkiDkQe-iADaUmS6s2Sb4rTKpGm57T4FpFEh2yGFQLL7Lw0Vro5yjP7N1akBaxTME2uTNeeFUdHKW73dLRdWzRMdpr_u9vnHUO_LD-pgO8C5CI3yjdshtSlW46U_bpDNU5a3X7Y=)**\n",
        "*   **[reply.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHWVYsfwpVf5uXe0TumwleMzHv5JW6z89iNjYMYeC9ZnF__dk9YtS3qsbTtuEB1NHXuejl_kxwAVhCVnGtDun1SHK4ZJeRqONqJZ11j4D1L2QSW-JTC71TbV0k8EkMW9izypdE6wmLbxZ59B6yC7VysNjYMbe8Op-ZWASymzrzlTQrppSD4J2yQg3xyCUr0ZiYUApY98zp9cXEEjty3x5mTm0c0OFbBol0=)**\n",
        "*   **[researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHFpaSsqwN_45WXDlZqdu5Iaebl75V-c_oY-BzQQ0QbXKLgPnEEtvW18sh1Q5Qpo7Qiktg4ox4wfbxStITnjWao4vKgHbL28z7waOY2PV-7YSkV8OZm5asQpe1dwvS32NuS1sUAESQcKwV2GytwW3gsVJejeH_Qou5gjRzx41TguJPgJLtTTpyjoZqLsgNeo0eIDP2JXyQ6ce7QS7xfG14QS2fPnL2lEnO1MKJWUDgpJcGoc2t6B21qskybUiM0c68g)**\n",
        "*   **[researchgate.net](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXE6tbPsI7cHz4gGFW4Ks0YW6pVvjx1beivjFFFFw3mhpORyW6uQUv2e_y74Qt0ET1G-SLbg_blabpHFJl_GlbcEUjbv847KGLQ_MoSOjURcEXB3mQY2T25ansxXM8rzKuKxhIrf7ayPicbtlzQxG9vDENVKWrktmK_urJ1_17IYoCG7zq6W2-AfVQqps2OT4EDrw1gQOG25zQzBwDJEVEm1Kyz0foY0COhghpSsls2kq86h9rOITUco8PdPjxXG2Q0dNitjehzZ10Bn7dc=)**\n",
        "*   **[salesforce.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEq5qh5QID-3VSv4v4MW2F0AZFQW5SckUenSbHkrJNM1VCD_BVSyQhHON7-UTWjR-HS3YhV-cic5sRRggTpg12X0dKF056iPF_xqspaj9Py7sroxZlmi9Dco6wKIIOH2gTGgjQfyxJ1ibnHkJENKaFPA4iXAtEhk9c_16UKAHXV)**\n",
        "*   **[servixon.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0VygXI9kJbfrTxImyfyEhrSRk_Ig84LXoqgS3g9qbhYSspbOv1W6HhJouwlYSE5c2RilO3JODP-nXLesDFVOfiHdgaxBvJjYTUrTrQahVHt9iaGRzmEjFehzwmO-zSaHdiOHJppseoqkbOgGz3jtq1vWuXV95OgoIeu8mU2aszF7qF5G7JzsPMOAcPYlhMcVuqxKmzPgoM-WI4cdsY6Baf8tbZw==)**\n",
        "*   **[skyflow.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFBJAg1vrfWJfd8YK7W4KBKxA_r824pyXuE_FffSByc-1087jTUgFPJYK8fId5DCzyOXwmCCgZ6Si0YTudarsDn0KJIv1Z8zN4V2Sb9aj2-BXsmF4VZhzpbimBq_t-OLn4mCrW9PkpbDOFxfe8A7NM=)**\n",
        "*   **[turing.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEgNxIKQcN9zpxRpw8t3oGbDc_CXBPSEx1Kzrg-5kHGzj9RjcNX1kqeyLv4MonJlmc2mmmX1tSj2qGWkpmCmUWL-3NJji6YPHYRmkvOsHw36gTumG9cNAqWQwR5cfqsurhdJfG0MdLSzfMqVw9r5w==)**\n",
        "*   **[valanor.co](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGCFFdlr8272YIWiRyszv645ciIGO4mokMK5VUJXONZqrcQz4B1R8Vj7spByqr5MgcZko_MzQRBTadCGGUZCML-pLwH1V1s9gnSCNPIp1mVyNakFCjPVjHA4Qf-ULykFv83yWhP3FZhrQFPiqc=)**\n",
        "*   **[wandb.ai](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHqzmhbgqfYX8LuS1nH9BE8pbckursDga9-hOIi2aAjyKvZbet7mu4NeYXTHvp38Sexe-MlZQT8TBL2EQoUTVdrzDkWkszvQAHzsDEZPk-qVp0PzoleFbr-3JP75-C2GUU3qgTletUV5D36SwHe-_-ZfuMhyQNx0W5cIrbyzRKrd34RLLtGKA7sIVZT2qlbbzI8ZUfchkryvUKs1uMpCnWdfCGMSFCK5p5TZcXMJaTrISQbi2VamjyX7A-jN5lOu8E=)**\n",
        "*   **[xcubelabs.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEMRZyjJJFxfM5TWt9EgMws-YHjS1kjOSd3bSpTfIZf66fHI4kypZv0qbe-hQQuRWblyLVbwt3yg2XDKgOb82ajZug5PwLUy3Z3G9gTN9bSXxqk5BFUor5XqlubUejFsEa-9bSbTtb60GY3FlXukNKoDNWDHEzCo7RSnuetmswMKAypUGosobIRG2F1JElcXe77aayBguQpb8UM-uTugjqU9Q==)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN35v80v6L_e"
      },
      "source": [
        "# 5.0 - BONUS: AGENT DEVELOPMENT KIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpQ4zjwX6IXf"
      },
      "outputs": [],
      "source": [
        "def roll_die(sides: int) -> int:\n",
        "  \"\"\"Roll a die and return the rolled result.\n",
        "\n",
        "  Args:\n",
        "    sides: The integer number of sides the die has.\n",
        "\n",
        "  Returns:\n",
        "    An integer of the result of rolling the die.\n",
        "  \"\"\"\n",
        "  import random\n",
        "\n",
        "  return random.randint(1, sides)\n",
        "\n",
        "def check_prime(nums: list[int]) -> list[str]:\n",
        "  \"\"\"Check if a given list of numbers are prime.\n",
        "\n",
        "  Args:\n",
        "    nums: The list of numbers to check.\n",
        "\n",
        "  Returns:\n",
        "    A str indicating which number is prime.\n",
        "  \"\"\"\n",
        "\n",
        "  primes = set()\n",
        "  for number in nums:\n",
        "    number = int(number)\n",
        "    if number <= 1:\n",
        "      continue\n",
        "    is_prime = True\n",
        "    for i in range(2, int(number**0.5) + 1):\n",
        "      if number % i == 0:\n",
        "        is_prime = False\n",
        "        break\n",
        "    if is_prime:\n",
        "      primes.add(number)\n",
        "  return (\n",
        "      'No prime numbers found.'\n",
        "      if not primes\n",
        "      else f\"{', '.join(str(num) for num in primes)} are prime numbers.\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb00DGJQqlVx",
        "outputId": "3b9ebba6-5184-4510-971e-d70524a8cc99"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.sessions import InMemorySessionService, VertexAiSessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "print(\"Libraries imported.\")\n",
        "\n",
        "MODEL = \"gemini-2.0-flash\"\n",
        "\n",
        "APP_NAME = 'TEST_APP'\n",
        "USER_ID = 'TEST_USER'\n",
        "\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"1\"\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION\n",
        "\n",
        "my_agent = Agent(\n",
        "    model=MODEL,\n",
        "    name='dice_rolling_agent',\n",
        "    instruction=\"\"\"\n",
        "      You roll dice and answer questions about the outcome of the dice rolls.\n",
        "      You can roll dice of different sizes.\n",
        "      You can use multiple tools in parallel by calling functions in parallel(in one request and in one round).\n",
        "      The only things you do are roll dice for the user and discuss the outcomes.\n",
        "      It is ok to discuss previous dice roles, and comment on the dice rolls.\n",
        "      When you are asked to roll a die, you must call the roll_die tool with the number of sides. Be sure to pass in an integer. Do not pass in a string.\n",
        "      You should never roll a die on your own.\n",
        "      When checking prime numbers, call the check_prime tool with a list of integers. Be sure to pass in a list of integers. You should never pass in a string.\n",
        "      You should not check prime numbers before calling the tool.\n",
        "      When you are asked to roll a die and check prime numbers, you should always make the following two function calls:\n",
        "      1. You should first call the roll_die tool to get a roll. Wait for the function response before calling the check_prime tool.\n",
        "      2. After you get the function response from roll_die tool, you should call the check_prime tool with the roll_die result.\n",
        "      3. If user asks you to check primes based on previous rolls, make sure you include the previous rolls in the list.\n",
        "      4. When you respond, you must include the roll_die result from step 1.\n",
        "      You should always perform the previous 3 steps when asking for a roll and checking prime numbers.\n",
        "      You should not rely on the previous history on prime results.\n",
        "      You may recap or summarize past conversations\n",
        "    \"\"\",\n",
        "    tools=[roll_die, check_prime],\n",
        ")\n",
        "\n",
        "print(f\"Agent '{my_agent.name}' created using model '{MODEL}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWsgwNAr5bRQ",
        "outputId": "d4e2683b-7630-479d-b996-bd18cf0e2da6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# @title Setup Session Service and Runner\n",
        "\n",
        "# --- Session Management ---\n",
        "# Key Concept: SessionService stores conversation history & state.\n",
        "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "# Define constants for identifying the interaction context\n",
        "APP_NAME = \"tutorial_app\"\n",
        "USER_ID = \"user_1\"\n",
        "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
        "\n",
        "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
        "# --- Runner ---\n",
        "# Key Concept: Runner orchestrates the agent execution loop.\n",
        "runner = Runner(\n",
        "    agent=my_agent, # The agent we want to run\n",
        "    app_name=APP_NAME,   # Associates runs with our app\n",
        "    session_service=session_service # Uses our session manager\n",
        ")\n",
        "print(f\"Runner created for agent '{runner.agent.name}'.\")\n",
        "\n",
        "# Clear any pre-existing sessions\n",
        "for session in await runner.session_service.list_sessions(app_name=APP_NAME, user_id=USER_ID):\n",
        "  await runner.session_service.delete_session(app_name=APP_NAME, user_id=USER_ID, session_id=session)\n",
        "\n",
        "await runner.session_service.create_session(\n",
        "    app_name=APP_NAME,\n",
        "    user_id=USER_ID,\n",
        "    session_id=SESSION_ID\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUXNCY9_5unz"
      },
      "outputs": [],
      "source": [
        "def call_agent(query: str):\n",
        "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
        "  print(f\"\\n>>> User Query: {query}\")\n",
        "\n",
        "  # Prepare the user's message in ADK format\n",
        "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "\n",
        "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
        "\n",
        "  # Key Concept: run_async executes the agent logic and yields Events.\n",
        "  # We iterate through events to find the final answer.\n",
        "  for event in runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content):\n",
        "      # You can uncomment the line below to see *all* events during execution\n",
        "      #print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
        "\n",
        "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
        "      if event.is_final_response():\n",
        "          if event.content and event.content.parts:\n",
        "             # Assuming text response in the first part\n",
        "             final_response_text = event.content.parts[0].text\n",
        "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
        "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
        "          # Add more checks here if needed (e.g., specific error codes)\n",
        "          break # Stop processing events once the final response is found\n",
        "\n",
        "  print(f\"<<< Agent Response: {final_response_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo1q8Wxy94uD",
        "outputId": "c97e71ed-aeee-4ec6-b640-01990e97d48a"
      },
      "outputs": [],
      "source": [
        "await runner.session_service.list_sessions(app_name=APP_NAME, user_id=USER_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e47oYBeZ5wjx",
        "outputId": "e8519dbb-31e0-4ed5-b2d3-e6d8ed26b8fb"
      },
      "outputs": [],
      "source": [
        "call_agent(\"Roll a d20 and tell me if the result is a prime number\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y27tqlNv5z_B",
        "outputId": "d0ae7295-262c-4517-eda5-2799859632a3"
      },
      "outputs": [],
      "source": [
        "# @title Run the Initial Conversation\n",
        "\n",
        "def run_conversation():\n",
        "    call_agent(\"Roll a d20\")\n",
        "    call_agent(\"What's the weather like?\") # Expecting the tool's error message\n",
        "    call_agent(\"Is 73 a prime number?\")\n",
        "    call_agent(\"Roll a d100\")\n",
        "    call_agent(\"Is 12312324 a prime number?\")\n",
        "\n",
        "\n",
        "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
        "run_conversation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qvNqKodGH8w",
        "outputId": "820f1ba4-6812-4010-92b5-71ec27aa1f5e"
      },
      "outputs": [],
      "source": [
        "# @title Use the Session to Retrieve Previous Rolls\n",
        "\n",
        "call_agent(\"\"\"Recap our conversation thus far as a markdown list\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THwry1LV52Ii",
        "outputId": "59d80434-2f15-4282-d127-bd6585ba854c"
      },
      "outputs": [],
      "source": [
        "# @title Check whether other rolls are prime\n",
        "# The agent can revisit its history and check previously unchecked values.\n",
        "\n",
        "call_agent(\"\"\"\n",
        "Recap our conversation thus far as a markdown list.\n",
        "If a roll hasn't been checked to ensure it's prime, check it now.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgK5J4DVGhC3"
      },
      "source": [
        "# THANK YOU!!\n",
        "\n",
        "This concludes our lab.\n",
        "\n",
        "Please check out other labs at [goo.gle/LuisLab](https://goo.gle/LuisLab) and **stay curious**!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27y9CkQ10nK5"
      },
      "source": [
        "# ADDITIONAL RESOURCES\n",
        "\n",
        "**Tools & SDKs:**\n",
        "* [Agent Development Kit](https://google.github.io/adk-docs/)\n",
        "* [Agent Starter Pack](https://github.com/GoogleCloudPlatform/agent-starter-pack)\n",
        "* [Sample ADK-based Research Agent](https://github.com/heiko-hotz/my-perplex-project)\n",
        "\n",
        "**Reading:**\n",
        "* [Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpKYvffI-uNf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
